! function() {
    try {
        var e = "undefined" != typeof window ? window : "undefined" != typeof global ? global : "undefined" != typeof self ? self : {},
            t = (new e.Error).stack;
        t && (e._sentryDebugIds = e._sentryDebugIds || {}, e._sentryDebugIds[t] = "afbb8f57-bbfd-4996-a5d2-96a31abbb003", e._sentryDebugIdIdentifier = "sentry-dbid-afbb8f57-bbfd-4996-a5d2-96a31abbb003")
    } catch (e) {}
}(), (self.webpackChunk_N_E = self.webpackChunk_N_E || []).push([
    [836], {
        6728: (e, t, a) => {
            "use strict";
            a.d(t, {
                A: () => i
            });
            var s, n = a(6540);

            function r() {
                return (r = Object.assign ? Object.assign.bind() : function(e) {
                    for (var t = 1; t < arguments.length; t++) {
                        var a = arguments[t];
                        for (var s in a)({}).hasOwnProperty.call(a, s) && (e[s] = a[s])
                    }
                    return e
                }).apply(null, arguments)
            }
            let i = function(e) {
                return n.createElement("svg", r({
                    xmlns: "http://www.w3.org/2000/svg",
                    fill: "none",
                    viewBox: "0 0 15 15"
                }, e), s || (s = n.createElement("path", {
                    fill: "currentColor",
                    d: "M7.219 10.295c-.563-.117-1.014-.37-1.313-.668C4.4 8.121 4.406 5.994 5.9 4.5l2.098-2.098c1.494-1.494 3.615-1.5 5.127.006 1.506 1.506 1.512 3.639.006 5.133l-1.611 1.6c.17-.58.07-1.248-.153-1.77l.75-.756c.938-.931.938-2.244-.006-3.193-.943-.938-2.256-.938-3.193 0L6.914 5.42c-.932.937-.932 2.25.012 3.193.316.317.803.533 1.377.598zM8.39 5.168c.556.117 1.007.375 1.306.668 1.506 1.506 1.5 3.633.006 5.127L7.605 13.06c-1.494 1.494-3.615 1.5-5.126-.006C.973 11.549.973 9.416 2.473 7.928l1.611-1.606c-.17.58-.07 1.254.152 1.776l-.75.75c-.937.937-.937 2.244.012 3.193.938.938 2.25.938 3.188 0l2.003-1.998c.938-.932.932-2.25-.011-3.193-.317-.317-.797-.534-1.377-.598z"
                })))
            }
        },
        5072: (e, t, a) => {
            (window.__NEXT_P = window.__NEXT_P || []).push(["/research/crossing_the_uncanny_valley_of_voice", function() {
                return a(578)
            }])
        },
        3949: (e, t, a) => {
            "use strict";
            a.d(t, {
                f: () => s
            });
            let s = {
                DEFAULT: 0,
                XS: 415,
                S: 650,
                MS: 768,
                M: 1024,
                ML: 1440,
                L: 1680,
                XL: 1920
            }
        },
        1407: (e, t, a) => {
            "use strict";
            a.d(t, {
                A: () => i
            });
            var s = a(4848),
                n = a(4164),
                r = a(5580);
            let i = e => {
                let {
                    children: t
                } = e;
                return (0, s.jsxs)(s.Fragment, {
                    children: [(0, s.jsxs)("div", {
                        className: "relative z-0",
                        children: [(0, s.jsxs)("div", {
                            className: "w-full bg-light1 relative z-10",
                            children: [(0, s.jsxs)("div", {
                                className: "max-w-screen-2xl mx-auto relative z-0",
                                children: [(0, s.jsx)("div", {
                                    className: (0, n.A)("relative", "pl-[var(--s28)] sm:pl-[var(--s32)] md:pl-[var(--s40)] lg:pl-[var(--s80)]", "bg-white md:bg-[transparent] "),
                                    children: (0, s.jsx)("div", {
                                        className: (0, n.A)("relative z-10", "grid grid-cols-6 gap-[var(--s20)] md:grid-cols-12", "pr-[var(--s28)] sm:pr-[var(--s32)] md:pr-[var(--s40)] lg:pr-[var(--s80)]", "relative z-10 min-h-[100dvh]"),
                                        children: (0, s.jsx)("div", {
                                            className: (0, n.A)("col-start-1 col-end-7", "md:col-start-3 md:col-end-13", " bg-white", "pt-[var(--s80)] md:pt-[var(--s200)]", "grid grid-cols-6 md:grid-cols-11 lg:grid-cols-10 gap-[var(--s20)]"),
                                            children: (0, s.jsx)("div", {
                                                className: (0, n.A)("col-start-1 col-end-7", "md:col-start-2 md:col-end-11", "lg:col-start-2 lg:col-end-9"),
                                                children: t
                                            })
                                        })
                                    })
                                }), (0, s.jsx)("div", {
                                    className: "absolute top-0 right-0 bottom-0 w-[50%] h-full bg-white"
                                })]
                            }), (0, s.jsx)("div", {
                                className: "absolute bottom-0 w-full rounded-b-radius1 h-[calc(2*var(--radius-1))] bg-light1 translate-y-[50%] z-10 overflow-hidden",
                                children: (0, s.jsxs)("div", {
                                    className: "max-w-screen-2xl mx-auto relative z-0",
                                    children: [(0, s.jsx)("div", {
                                        className: (0, n.A)("relative", "pl-[var(--s28)] sm:pl-[var(--s32)] md:pl-[var(--s40)] lg:pl-[var(--s80)]", "bg-white md:bg-[transparent] "),
                                        children: (0, s.jsx)("div", {
                                            className: (0, n.A)("relative z-10", "grid grid-cols-6 gap-[var(--s20)] md:grid-cols-12", "pr-[var(--s28)] sm:pr-[var(--s32)] md:pr-[var(--s40)] lg:pr-[var(--s80)]", "relative z-10 min-h-[100dvh]"),
                                            children: (0, s.jsx)("div", {
                                                className: (0, n.A)("col-start-1 col-end-7", "md:col-start-3 md:col-end-13", " bg-white", "grid grid-cols-6 md:grid-cols-11 lg:grid-cols-10 gap-[var(--s20)]")
                                            })
                                        })
                                    }), (0, s.jsx)("div", {
                                        className: "absolute top-0 right-0 bottom-0 w-[50%] h-full bg-white"
                                    })]
                                })
                            })]
                        }), (0, s.jsx)(r.A, {
                            "data-sentry-element": "Footer",
                            "data-sentry-source-file": "ResearchPageLayout.tsx"
                        })]
                    }), (0, s.jsx)("style", {
                        children: "\n            body{\n              background-color: white;\n            }\n          "
                    })]
                })
            }
        },
        3591: (e, t, a) => {
            "use strict";
            a.d(t, {
                A: () => r
            });
            var s = a(4848);
            a(6540);
            var n = a(4164);
            let r = e => {
                let {
                    icon: t,
                    text: a,
                    onClick: r,
                    variant: i = "brand",
                    disabled: l = !1,
                    className: o
                } = e;
                return (0, s.jsxs)("button", {
                    onClick: r,
                    disabled: l,
                    className: (0, n.A)("flex items-center justify-center gap-2 rounded-xl shadow-subtle box-border border border-transparent px-[var(--s16px)] py-[var(--s12px)]", "relative w-full", "brand" === i ? "bg-buttonBrandBackgroundNormal hover:bg-buttonBrandBackgroundActive active:bg-buttonBrandBackgroundActive active:border-active" : "bg-white hover:bg-buttonPrimaryBackgroundActive active:bg-buttonPrimaryBackgroundActivee active:border-active", "disabled:bg-gray-100 disabled:cursor-not-allowed", "transition-colors duration-200", o),
                    "data-sentry-component": "ElevatedButton",
                    "data-sentry-source-file": "ElevatedButton.tsx",
                    children: [null != t ? (0, s.jsx)("span", {
                        className: "flex-shrink-0",
                        children: t
                    }) : null, (0, s.jsx)("span", {
                        className: "text-md font-medium text-secondary flex-1",
                        children: a
                    }), (0, s.jsx)("span", {
                        className: "flex-shrink-0 invisible",
                        children: t
                    })]
                })
            }
        },
        8592: (e, t, a) => {
            "use strict";
            a.d(t, {
                A: () => n
            });
            var s = a(4848);

            function n(e) {
                let {
                    fillColor: t
                } = e;
                return (0, s.jsxs)("svg", {
                    version: "1.1",
                    xmlns: "http://www.w3.org/2000/svg",
                    viewBox: "0 0 48 48",
                    width: "24px",
                    height: "24px",
                    "data-sentry-element": "svg",
                    "data-sentry-component": "GoogleIcon",
                    "data-sentry-source-file": "GoogleIcon.tsx",
                    children: [(0, s.jsx)("path", {
                        fill: null != t ? t : "#EA4335",
                        d: "M24 9.5c3.54 0 6.71 1.22 9.21 3.6l6.85-6.85C35.9 2.38 30.47 0 24 0 14.62 0 6.51 5.38 2.56 13.22l7.98 6.19C12.43 13.72 17.74 9.5 24 9.5z",
                        "data-sentry-element": "path",
                        "data-sentry-source-file": "GoogleIcon.tsx"
                    }), (0, s.jsx)("path", {
                        fill: null != t ? t : "#4285F4",
                        d: "M46.98 24.55c0-1.57-.15-3.09-.38-4.55H24v9.02h12.94c-.58 2.96-2.26 5.48-4.78 7.18l7.73 6c4.51-4.18 7.09-10.36 7.09-17.65z",
                        "data-sentry-element": "path",
                        "data-sentry-source-file": "GoogleIcon.tsx"
                    }), (0, s.jsx)("path", {
                        fill: null != t ? t : "#FBBC05",
                        d: "M10.53 28.59c-.48-1.45-.76-2.99-.76-4.59s.27-3.14.76-4.59l-7.98-6.19C.92 16.46 0 20.12 0 24c0 3.88.92 7.54 2.56 10.78l7.97-6.19z",
                        "data-sentry-element": "path",
                        "data-sentry-source-file": "GoogleIcon.tsx"
                    }), (0, s.jsx)("path", {
                        fill: null != t ? t : "#34A853",
                        d: "M24 48c6.48 0 11.93-2.13 15.89-5.81l-7.73-6c-2.15 1.45-4.92 2.3-8.16 2.3-6.26 0-11.57-4.22-13.47-9.91l-7.98 6.19C6.51 42.62 14.62 48 24 48z",
                        "data-sentry-element": "path",
                        "data-sentry-source-file": "GoogleIcon.tsx"
                    }), (0, s.jsx)("path", {
                        fill: "none",
                        d: "M0 0h48v48H0z",
                        "data-sentry-element": "path",
                        "data-sentry-source-file": "GoogleIcon.tsx"
                    })]
                })
            }
            a(6540)
        },
        578: (e, t, a) => {
            "use strict";
            a.r(t), a.d(t, {
                __N_SSG: () => eA,
                default: () => eM
            });
            var s, n = a(4848),
                r = a(6540),
                i = a(2558),
                l = a(6557),
                o = a(1407);
            let c = e => {
                let {
                    src: t
                } = e, [a, s] = (0, r.useState)(!1), [i, l] = (0, r.useState)(0), [o, c] = (0, r.useState)(0), d = (0, r.useRef)(null), u = (0, r.useRef)(null);
                (0, r.useEffect)(() => {
                    if (d.current) {
                        let e = d.current,
                            t = () => {
                                e.duration && 0 !== e.duration && 0 === o && c(e.duration)
                            },
                            a = () => {
                                t(), u.current && l(e.currentTime)
                            };
                        return t(), e.addEventListener("loadedmetadata", t), e.addEventListener("timeupdate", a), e.addEventListener("ended", () => s(!1)), e.volume = 1, () => {
                            e.removeEventListener("loadedmetadata", t), e.removeEventListener("timeupdate", a), e.removeEventListener("ended", () => s(!1))
                        }
                    }
                }, [d.current, o]);
                let h = e => {
                    let t = Math.floor(e / 60).toString().padStart(2, "0"),
                        a = Math.floor(e % 60).toString().padStart(2, "0");
                    return "".concat(t, ":").concat(a)
                };
                return (0, n.jsxs)("div", {
                    className: "w-full bg-green7 rounded-[var(--s4)] text-body md:text-sidebar-light text-[#7E8460] py-[var(--s8)] pl-[var(--s8)] pr-[var(--s18)]",
                    "data-sentry-component": "AudioPlayer",
                    "data-sentry-source-file": "Audio.tsx",
                    children: [(0, n.jsxs)("div", {
                        className: "flex items-center gap-[var(--s10)]",
                        children: [(0, n.jsx)("button", {
                            onClick: () => {
                                d.current && (a ? d.current.pause() : d.current.play(), s(!a))
                            },
                            className: "focus:outline-none w-[var(--s32)] h-[var(--s32)] relative flex justify-center items-center",
                            "aria-label": a ? "Pause" : "Play",
                            children: a ? (0, n.jsxs)("svg", {
                                width: "24",
                                height: "24",
                                viewBox: "0 0 24 24",
                                className: "text-olive-600 fill-current",
                                children: [(0, n.jsx)("rect", {
                                    x: "6",
                                    y: "4",
                                    width: "4",
                                    height: "16"
                                }), (0, n.jsx)("rect", {
                                    x: "14",
                                    y: "4",
                                    width: "4",
                                    height: "16"
                                })]
                            }) : (0, n.jsx)("svg", {
                                width: "13",
                                height: "16",
                                viewBox: "0 0 13 16",
                                fill: "none",
                                xmlns: "http://www.w3.org/2000/svg",
                                children: (0, n.jsx)("path", {
                                    d: "M0 2.66333C0 1.081 1.75049 0.125316 3.08152 0.980974L11.383 6.31764C12.6076 7.10492 12.6076 8.89508 11.383 9.68236L3.08152 15.019C1.75049 15.8747 0 14.919 0 13.3367V2.66333Z",
                                    fill: "rgb(91, 101, 42)"
                                })
                            })
                        }), (0, n.jsxs)("div", {
                            className: "flex-grow relative flex gap-[var(--s12)] items-center",
                            children: [(0, n.jsx)("div", {
                                className: "min-w-[var(--s46)] w-[var(--s46)] shrink-0",
                                children: h(i)
                            }), (0, n.jsxs)("div", {
                                className: "flex-grow relative h-[var(--s6)]",
                                children: [(0, n.jsx)("input", {
                                    ref: u,
                                    type: "range",
                                    min: "0",
                                    step: .01,
                                    max: o,
                                    value: i,
                                    onChange: e => {
                                        let t = parseFloat(e.target.value);
                                        l(t), d.current && (d.current.currentTime = t)
                                    },
                                    className: "block w-full absolute top-[50%] translate-y-[-50%] appearance-none [&::-webkit-slider-thumb]:mt-[-5px] bg-[tranparent] [&::-webkit-slider-thumb]:invisible [&::-moz-range-thumb]:invisible"
                                }), (0, n.jsxs)("div", {
                                    className: "absolute h-full rounded-full pointer-events-none w-full top-[50%] translate-y-[-50%]",
                                    children: [(0, n.jsx)("div", {
                                        className: "h-full bg-green6 rounded-full",
                                        style: {
                                            width: "".concat(i / (o || 1) * 100, "%")
                                        }
                                    }), (0, n.jsx)("div", {
                                        className: "w-[var(--s10)] h-[var(--s10)] bg-green6 rounded-full absolute top-[50%] translate-y-[-50%] translate-x-[-50%]",
                                        style: {
                                            left: "".concat(i / (o || 1) * 100, "%")
                                        }
                                    })]
                                })]
                            }), (0, n.jsx)("div", {
                                children: h(o)
                            })]
                        })]
                    }), (0, n.jsx)("audio", {
                        ref: d,
                        src: t,
                        preload: "metadata"
                    })]
                })
            };
            var d = a(424),
                u = a(6880),
                h = a(9464),
                m = a(6715),
                p = a(6620),
                f = a(6372),
                x = a(7882),
                v = a(3804),
                g = a(6480),
                y = a(573),
                b = a(3866);
            class w {
                setAudio(e) {
                    this.audio = e
                }
                useWebm() {
                    var e, t, a, s;
                    let n = u.parse(window.navigator.userAgent),
                        r = (null === (e = n.browser.name) || void 0 === e ? void 0 : e.toLowerCase()) === "safari",
                        i = (null === (t = n.os.name) || void 0 === t ? void 0 : t.toLowerCase()) === "macos",
                        l = (null === (a = n.browser.name) || void 0 === a ? void 0 : a.toLowerCase()) === "firefox",
                        o = (null === (s = n.os.name) || void 0 === s ? void 0 : s.toLowerCase()) === "ios";
                    return l || !o && !r && !i
                }
                record(e) {
                    var t;
                    let {
                        frameRate: a,
                        maxDurationS: s
                    } = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {};
                    this.stop(), this.audio = null, this.chunks = null;
                    let n = this.useWebm() ? "video/webm; codecs=vp9" : "video/mp4";
                    (null === (t = u.parse(window.navigator.userAgent).browser.name) || void 0 === t ? void 0 : t.toLowerCase()) === "firefox" && (n = "video/webm");
                    let r = e.captureStream(a);
                    this.mediaRecorder = new MediaRecorder(r, {
                        mimeType: n
                    }), console.log("MediaRecorder MIME type:", this.mediaRecorder.mimeType);
                    let i = [],
                        l = Date.now();
                    this.mediaRecorder.addEventListener("dataavailable", e => {
                        i.push(e.data), s && Date.now() - l > 1e3 * s && (console.log("Max duration reached"), i = [], this.stop())
                    }), this.mediaRecorder.addEventListener("stop", () => {
                        i.length > 0 && (this.chunks = i, console.log("Blob type:", i[0].type))
                    }), this.mediaRecorder.start(1e3)
                }
                stop() {
                    return !!this.mediaRecorder && (this.mediaRecorder.stop(), this.mediaRecorder = null, !0)
                }
                async finalizeVideo(e) {
                    if (!this.audio || !this.chunks) return null;
                    this.ffmpeg || (this.ffmpeg = await this.loader()), this.ffmpeg.on("progress", t => {
                        let {
                            progress: a,
                            time: s
                        } = t;
                        null == e || e(a)
                    });
                    let t = new b.A;
                    t.fromScratch(1, this.audio.inputSampleRate, "16", this.audio.input);
                    let a = new b.A;
                    a.fromScratch(1, this.audio.outputSampleRate, "16", this.audio.output);
                    let s = new Blob([t.toBuffer()], {
                            type: "audio/wav"
                        }),
                        n = new Blob([a.toBuffer()], {
                            type: "audio/wav"
                        }),
                        r = this.useWebm(),
                        i = r ? "webm" : "mp4",
                        l = "video/".concat(i),
                        o = "video.".concat(i),
                        c = new Blob(this.chunks, {
                            type: l
                        });
                    this.ffmpeg.writeFile(o, await (0, y.t2)(c)), this.ffmpeg.writeFile("audio1.wav", await (0, y.t2)(s)), this.ffmpeg.writeFile("audio2.wav", await (0, y.t2)(n));
                    let d = Date.now();
                    await this.ffmpeg.exec(["-i", "audio1.wav", "-i", "audio2.wav", "-filter_complex", "amix=inputs=2:duration=longest", "audio.wav"]), await this.ffmpeg.exec(["-i", o, "-i", "audio.wav", "-filter:a", "loudnorm", "-c:v", "copy", "-c:a", r ? "libopus" : "aac", "-b:a", r ? "64k" : "128k", "-shortest", "output.".concat(i)]), console.log("Video encoding time", (Date.now() - d) / 1e3);
                    let u = await this.ffmpeg.readFile("output.".concat(i));
                    console.log("Video size:", u.byteLength);
                    let h = new Blob([u.buffer], {
                        type: l
                    });
                    return this.chunks = null, this.audio = null, {
                        blob: h,
                        extension: i
                    }
                }
                constructor(e) {
                    this.audio = null, this.mediaRecorder = null, this.chunks = null, this.ffmpeg = null, this.loader = e
                }
            }
            var j = a(4164);

            function N(e) {
                return (N = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function(e) {
                    return typeof e
                } : function(e) {
                    return e && "function" == typeof Symbol && e.constructor === Symbol && e !== Symbol.prototype ? "symbol" : typeof e
                })(e)
            }

            function _() {
                return (_ = Object.assign ? Object.assign.bind() : function(e) {
                    for (var t = 1; t < arguments.length; t++) {
                        var a = arguments[t];
                        for (var s in a)({}).hasOwnProperty.call(a, s) && (e[s] = a[s])
                    }
                    return e
                }).apply(null, arguments)
            }

            function k(e, t, a) {
                var s;
                return (s = function(e, t) {
                    if ("object" != N(e) || !e) return e;
                    var a = e[Symbol.toPrimitive];
                    if (void 0 !== a) {
                        var s = a.call(e, t || "default");
                        if ("object" != N(s)) return s;
                        throw TypeError("@@toPrimitive must return a primitive value.")
                    }
                    return ("string" === t ? String : Number)(e)
                }(t, "string"), (t = "symbol" == N(s) ? s : s + "") in e) ? Object.defineProperty(e, t, {
                    value: a,
                    enumerable: !0,
                    configurable: !0,
                    writable: !0
                }) : e[t] = a, e
            }
            let C = function(e) {
                return r.createElement("svg", _({
                    xmlns: "http://www.w3.org/2000/svg",
                    fill: "none",
                    viewBox: "0 0 30 30"
                }, e), r.createElement("path", {
                    fill: "#5B652A",
                    d: "M4.898 14.39V12.2q0-.657.47-1.102.48-.446 1.136-.446t1.137.446q.492.446.492 1.101v2.086q0 1.992.89 3.469a6.1 6.1 0 0 0 2.438 2.285q1.559.81 3.539.809 1.98 0 3.527-.809a6.06 6.06 0 0 0 2.45-2.285q.902-1.477.902-3.469V12.2q0-.655.469-1.101a1.63 1.63 0 0 1 1.148-.446q.668 0 1.137.446t.469 1.101v2.192q0 2.67-1.114 4.687a8.65 8.65 0 0 1-3.047 3.235q-1.944 1.218-4.43 1.511v1.664h4.196q.656 0 1.137.457.492.457.492 1.125 0 .634-.492 1.102-.48.468-1.137.469H9.293q-.657 0-1.148-.47-.48-.468-.48-1.1 0-.669.48-1.126.492-.456 1.148-.457H13.5v-1.664q-2.496-.293-4.441-1.512a8.8 8.8 0 0 1-3.047-3.234q-1.113-2.016-1.114-4.687M15 18.634q-1.23 0-2.285-.574a4.5 4.5 0 0 1-1.676-1.641q-.633-1.054-.633-2.461V5.941q0-1.405.633-2.449.633-1.055 1.676-1.64A4.63 4.63 0 0 1 15 1.266q1.23 0 2.273.586 1.043.585 1.665 1.64.632 1.055.632 2.461v8.004q0 1.407-.633 2.461a4.4 4.4 0 0 1-1.664 1.64 4.64 4.64 0 0 1-2.273.575",
                    style: k(k({
                        fill: "#5b652a"
                    }, "fill", "color(display-p3 .3569 .3961 .1647)"), "fillOpacity", 1)
                }))
            };

            function S(e) {
                return (S = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function(e) {
                    return typeof e
                } : function(e) {
                    return e && "function" == typeof Symbol && e.constructor === Symbol && e !== Symbol.prototype ? "symbol" : typeof e
                })(e)
            }

            function A() {
                return (A = Object.assign ? Object.assign.bind() : function(e) {
                    for (var t = 1; t < arguments.length; t++) {
                        var a = arguments[t];
                        for (var s in a)({}).hasOwnProperty.call(a, s) && (e[s] = a[s])
                    }
                    return e
                }).apply(null, arguments)
            }

            function M(e, t, a) {
                var s;
                return (s = function(e, t) {
                    if ("object" != S(e) || !e) return e;
                    var a = e[Symbol.toPrimitive];
                    if (void 0 !== a) {
                        var s = a.call(e, t || "default");
                        if ("object" != S(s)) return s;
                        throw TypeError("@@toPrimitive must return a primitive value.")
                    }
                    return ("string" === t ? String : Number)(e)
                }(t, "string"), (t = "symbol" == S(s) ? s : s + "") in e) ? Object.defineProperty(e, t, {
                    value: a,
                    enumerable: !0,
                    configurable: !0,
                    writable: !0
                }) : e[t] = a, e
            }
            let E = function(e) {
                    return r.createElement("svg", A({
                        xmlns: "http://www.w3.org/2000/svg",
                        fill: "none",
                        viewBox: "0 0 30 30"
                    }, e), r.createElement("path", {
                        fill: "#5B652A",
                        d: "M4.898 14.39V12.2q0-.657.47-1.102.48-.446 1.136-.446t1.137.446q.492.446.492 1.101v2.086q0 1.992.89 3.469a6.1 6.1 0 0 0 2.438 2.285q1.559.81 3.539.809.973 0 1.852-.2a7.2 7.2 0 0 0 1.64-.597l2.32 2.332a9.5 9.5 0 0 1-2.015.937q-1.09.363-2.285.504v1.664h4.195q.656 0 1.137.457.492.457.492 1.125 0 .634-.492 1.102-.48.468-1.137.469H9.293q-.657 0-1.148-.47-.48-.468-.48-1.1 0-.669.48-1.126.492-.456 1.148-.457H13.5v-1.664q-2.496-.293-4.441-1.512a8.8 8.8 0 0 1-3.047-3.234q-1.113-2.016-1.114-4.687m16.77 1.43q.21-.726.21-1.535V12.2q0-.655.47-1.101a1.63 1.63 0 0 1 1.148-.446q.668 0 1.137.446t.469 1.101v2.192q0 2.226-.809 4.054zM15 18.633q-1.23 0-2.285-.574a4.5 4.5 0 0 1-1.676-1.641q-.633-1.054-.633-2.461v-1.992l6.317 6.316a4.3 4.3 0 0 1-1.723.352M15 1.43q-1.02 0-1.887.41a4.2 4.2 0 0 0-1.488 1.137 4.34 4.34 0 0 0-.879 1.746v.187l8.813 8.813a.6.6 0 0 0 .011-.118V6.117q0-1.406-.633-2.46a4.4 4.4 0 0 0-1.664-1.641A4.56 4.56 0 0 0 15 1.43m9.938 22.77L4.816 4.112a.95.95 0 0 1-.28-.703q0-.433.28-.715a1 1 0 0 1 .715-.293q.423 0 .715.293l20.11 20.086a.97.97 0 0 1 .292.715.96.96 0 0 1-.293.703.94.94 0 0 1-.703.293.97.97 0 0 1-.715-.293",
                        style: M(M({
                            fill: "#5b652a"
                        }, "fill", "color(display-p3 .3569 .3961 .1647)"), "fillOpacity", 1)
                    }))
                },
                R = e => {
                    let {
                        timerIsRunning: t
                    } = e, a = (0, r.useRef)(null), [s, i] = (0, r.useState)(0);
                    (0, r.useEffect)(() => {
                        let e = null;
                        return t && (e = setInterval(() => {
                            i(e => e + 1)
                        }, 1e3)), () => {
                            e && clearInterval(e)
                        }
                    }, [t]);
                    let l = Math.floor(s / 60),
                        o = "".concat(String(l).padStart(2, "0"), ":").concat(String(s % 60).padStart(2, "0"));
                    return (0, n.jsx)("div", {
                        "data-sentry-component": "CallButtonTimer",
                        "data-sentry-source-file": "callButtonTimer.tsx",
                        children: (0, n.jsx)("p", {
                            ref: a,
                            children: o
                        })
                    })
                };

            function z(e) {
                return "Sorry, ".concat(e, " couldn’t pick up the call. Please call back later.")
            }
            let P = {
                    serviceUnavailable: z,
                    micInputNotDetected: "Microphone input not detected. Please refresh your browser.",
                    callDropped: "The call failed. Please try again later.",
                    poorConnection: "Network latency may be affecting your call. If possible, try switching to a better connection.",
                    maxDurationMessage: e => "".concat(e, " enjoyed your call, please feel free to call again"),
                    unknownError: z,
                    microphoneAccessDenied: "Unable to request microphone permission, please update your browser system settings to enable.",
                    backgroundCallEnded: "Call ended by closing or minimizing browser, feel free to call back!",
                    warnSafari175: "This browser version (17.5) may result in degraded audio quality.",
                    videoFailed: "Failed to download clip.",
                    microphoneAccessPrompt: e => "To chat with ".concat(e, ", please allow us to use your microphone."),
                    connecting: e => "Connecting to ".concat(e, "..."),
                    pressToStart: "Press to start a conversation",
                    loggedInVisualizerSubtextDefault: "You're logged in with Google.",
                    loggedInVisualizerSubtextWithEmail: e => "You're logged in as ".concat(e, "."),
                    emailLabel: "Email",
                    emailPlaceholder: "Leave an email, receive our latest updates",
                    thankYouForSigningUp: "Thank you for signing up!",
                    webgl_unavailable: "WebGL is unavailable for animation.",
                    webgl_context_lost: "WebGL is unavailable for animation.",
                    endCall: "End call",
                    mute: "Mute",
                    unmute: "Unmute",
                    downloadClip: "Download clip",
                    downloadNow: "Download now",
                    preparingClip: "Preparing clip... ",
                    skip: "Skip",
                    signup: "Sign Up",
                    done: "Done",
                    maya: "Maya",
                    miles: "Miles",
                    feedbackButton: e => "Share your feedback for ".concat(e)
                },
                T = r.forwardRef((e, t) => {
                    let {
                        onEndCall: a,
                        character: s,
                        callIsActive: i,
                        onMute: l,
                        onUnmute: o,
                        children: c,
                        callWarning: d
                    } = e, [u, h] = (0, r.useState)(!1), m = (0, r.useRef)(null), p = (0, r.useRef)(null), f = (0, r.useRef)(null);
                    (0, r.useEffect)(() => {
                        let e = m.current,
                            t = p.current;
                        e && t && setTimeout(() => {
                            e.classList.add("active"), t.classList.add("active")
                        }, 400)
                    }, []);
                    let x = e => {
                        let t = m.current,
                            a = p.current,
                            s = f.current;
                        t.classList.remove("active"), a.classList.remove("active"), s && (s.style.opacity = "0"), setTimeout(() => {
                            e()
                        }, 700)
                    };
                    return (0, r.useImperativeHandle)(t, () => ({
                        onClickEndCall: x
                    })), (0, n.jsxs)("div", {
                        className: (0, j.A)("absolute inset-0 md:px-[var(--s32)] md:py-[var(--s24)] justify-between md:items-center z-10", "flex flex-col md:flex-row", "select-none"),
                        children: [(0, n.jsx)("div", {
                            children: (0, n.jsxs)("div", {
                                className: (0, j.A)("p-[var(--s16)] md:p-0", "w-full md:w-auto", "fadeFromLeft"),
                                ref: m,
                                children: [(0, n.jsxs)("div", {
                                    className: "flex md:flex-col justify-between items-center md:items-start select-none",
                                    children: [(0, n.jsx)("div", {
                                        children: (0, n.jsxs)("div", {
                                            className: (0, j.A)("text-green2 flex items-center gap-[var(--s8)]"),
                                            children: [(0, n.jsx)("p", {
                                                className: "text-sidebar",
                                                "aria-label": s,
                                                children: s
                                            }), (0, n.jsx)(R, {
                                                timerIsRunning: i
                                            })]
                                        })
                                    }), (0, n.jsx)("div", {
                                        className: "text-sidebar-light text-green3",
                                        "aria-label": "Sesame",
                                        children: "Sesame"
                                    })]
                                }), d && (0, n.jsx)("div", {
                                    className: "block md:hidden text-caption text-green6 opacity-40 mt-[var(--s8)] max-w-[var(--s128)]",
                                    children: d
                                })]
                            })
                        }), (0, n.jsx)("div", {
                            className: "w-full md:w-auto",
                            children: (0, n.jsxs)("div", {
                                ref: p,
                                className: "flex md:flex-col bg-green5 md:rounded-radius2 overflow-hidden  fadeFromRight",
                                children: [(0, n.jsx)(I, {
                                    onClick: () => {
                                        h(e => (e ? o() : l(), !e))
                                    },
                                    children: u ? (0, n.jsxs)(n.Fragment, {
                                        children: [(0, n.jsx)(E, {
                                            className: "h-[var(--s20)] w-[var(--s20)]"
                                        }), P.unmute]
                                    }) : (0, n.jsxs)(n.Fragment, {
                                        children: [(0, n.jsx)(C, {
                                            className: "h-[var(--s20)] w-[var(--s20)]"
                                        }), P.mute]
                                    })
                                }), (0, n.jsxs)(I, {
                                    onClick: () => {
                                        x(a)
                                    },
                                    children: [(0, n.jsx)("span", {
                                        className: "bg-rose-500 rounded-[var(--s2)] w-[var(--s16)] h-[var(--s16)] md:mr-[var(--s16)]"
                                    }), P.endCall]
                                })]
                            })
                        }), d && (0, n.jsx)("div", {
                            ref: f,
                            className: "hidden md:block absolute bottom-[var(--s68)] md:bottom-[var(--s12)] left-[50%] translate-x-[-50%] text-sidebar-light text-green3 text-center transition-opacity duration-300",
                            children: d
                        }), (0, n.jsx)("style", {
                            children: "\n            .fadeFromLeft\n            {\n              opacity: 0;\n              transition: opacity 0.4s, transform 0.4s;\n            \n              @media screen and (min-width: 768px) {\n                transform: translateX(-25%);\n              }\n            }\n\n            .fadeFromLeft.active\n            {\n              opacity: 1;\n              transform: translateX(0);\n            }\n\n            .fadeFromRight\n            {\n              opacity: 0;\n              transition: opacity 0.4s, transform 0.4s;\n            \n              @media screen and (min-width: 768px) {\n                transform: translateX(25%);\n              }\n            }\n\n            .fadeFromRight.active\n            {\n              opacity: 1;\n              transform: translateX(0);\n            }\n            \n          "
                        })]
                    })
                });
            T.displayName = "ButtonCallView";
            let I = e => {
                let {
                    children: t,
                    className: a,
                    ...s
                } = e;
                return (0, n.jsxs)("button", { ...s,
                    className: (0, j.A)("relative w-full p-[var(--s16)]", "text-callbutton text-green2", "group", a),
                    "data-sentry-component": "Button",
                    "data-sentry-source-file": "buttonCallView.tsx",
                    children: [(0, n.jsx)("span", {
                        className: "relative z-10 flex justify-center md:justify-between items-center gap-[var(--s12)] md:gap-0",
                        children: t
                    }), (0, n.jsx)("span", {
                        className: "hidden-touch group-hover:opacity-100 opacity-0 transition-opacity duration-300 bg-mayaBase absolute inset-0 z-[0]"
                    })]
                })
            };

            function B() {
                return (B = Object.assign ? Object.assign.bind() : function(e) {
                    for (var t = 1; t < arguments.length; t++) {
                        var a = arguments[t];
                        for (var s in a)({}).hasOwnProperty.call(a, s) && (e[s] = a[s])
                    }
                    return e
                }).apply(null, arguments)
            }
            let L = function(e) {
                    return r.createElement("svg", B({
                        xmlns: "http://www.w3.org/2000/svg",
                        fill: "none",
                        viewBox: "0 0 19 19"
                    }, e), s || (s = r.createElement("path", {
                        fill: "currentColor",
                        d: "M5.408 13.373C2.586 10.561.448 7.163.448 4.359c0-1.24.42-2.363 1.366-3.271C2.391.53 3.054.238 3.7.238c.528 0 1.016.205 1.348.674l2.1 2.96c.332.458.488.839.488 1.19 0 .45-.264.84-.694 1.29l-.693.712a.5.5 0 0 0-.146.362c0 .146.058.283.107.39.312.606 1.201 1.641 2.158 2.598.967.957 2.002 1.846 2.608 2.168a.9.9 0 0 0 .39.107.53.53 0 0 0 .371-.156l.694-.683c.449-.44.85-.694 1.289-.694.351 0 .742.156 1.191.469l2.998 2.129c.46.332.645.8.645 1.289 0 .664-.322 1.338-.84 1.914-.889.977-1.992 1.416-3.252 1.416-2.803 0-6.23-2.178-9.053-5"
                    })))
                },
                D = e => {
                    let {
                        character: t,
                        onAnimationEnd: a
                    } = e, s = (0, r.useRef)(null), i = (0, r.useRef)(null), l = (0, r.useRef)(null), o = (0, r.useRef)(null), c = (0, r.useRef)(null);
                    (0, r.useEffect)(() => {
                        let e = "Maya" === t ? i : o;
                        h.Ay.set([s.current, e.current], {
                            opacity: 0,
                            autoAlpha: 1
                        }), d()
                    }, []);
                    let d = () => {
                        let e = "Maya" === t ? l : c,
                            n = "Maya" === t ? i : o;
                        h.Ay.to(s.current, {
                            opacity: 1,
                            duration: .3,
                            delay: .1,
                            onComplete: () => {
                                let t = h.Ay.timeline({
                                    delay: .01
                                });
                                t.to(e.current, {
                                    scaleX: .5,
                                    duration: .5
                                }, 0), t.to(n.current, {
                                    opacity: 1,
                                    duration: .5
                                }, 0), t.call(() => {
                                    a()
                                })
                            }
                        })
                    };
                    return (0, n.jsxs)("div", {
                        ref: s,
                        className: "absolute inset-0 invisible",
                        "data-sentry-component": "ButtonCallChoiceIntro",
                        "data-sentry-source-file": "buttonCallChoiceIntro.tsx",
                        children: [(0, n.jsx)("div", {
                            className: (0, j.A)("absolute left-0 h-full origin-left bg-mayaBase", "Maya" === t ? "w-full" : "w-[50%]"),
                            style: {
                                zIndex: "Maya" === t ? 30 : 0
                            },
                            ref: l
                        }), (0, n.jsx)("div", {
                            ref: c,
                            className: (0, j.A)("absolute right-0 h-full w-[50%] z-0 origin-right bg-milesBase", "Miles" === t ? "w-full" : "w-[50%]"),
                            style: {
                                zIndex: "Miles" === t ? 30 : 0
                            }
                        }), (0, n.jsxs)("div", {
                            ref: o,
                            className: (0, j.A)("absolute top-[50%] right-[25%] flex gap-[var(--s8)] items-center text-green2 translate-x-[50%] translate-y-[-50%]", "Miles" === t && "invisible"),
                            style: {
                                zIndex: "Miles" === t ? 40 : 10
                            },
                            children: [(0, n.jsx)(L, {
                                className: "w-[var(--s16)] h-[var(--s16)]",
                                "data-sentry-element": "PhoneCallIcon",
                                "data-sentry-source-file": "buttonCallChoiceIntro.tsx"
                            }), (0, n.jsx)("p", {
                                className: "text-sidebar select-none",
                                children: "Miles"
                            })]
                        }), (0, n.jsxs)("div", {
                            className: (0, j.A)("absolute top-[50%] left-[25%] flex gap-[var(--s8)] items-center text-green2 translate-x-[-50%] translate-y-[-50%]", "Maya" === t && "invisible"),
                            ref: i,
                            style: {
                                zIndex: "Maya" === t ? 40 : 10
                            },
                            children: [(0, n.jsx)(L, {
                                className: "w-[var(--s16)] h-[var(--s16)]",
                                "data-sentry-element": "PhoneCallIcon",
                                "data-sentry-source-file": "buttonCallChoiceIntro.tsx"
                            }), (0, n.jsx)("p", {
                                className: "text-sidebar select-none",
                                children: "Maya"
                            })]
                        })]
                    })
                },
                O = e => {
                    let {
                        onClickChoice: t,
                        onOutroEnd: a,
                        animateIntro: s,
                        character: i,
                        onIntroEnd: l
                    } = e, o = (0, r.useRef)(null), c = (0, r.useRef)(!1), d = (0, r.useRef)(null), u = (0, r.useRef)(null), h = (0, r.useRef)(null), m = (0, r.useRef)(null), p = e => {
                        if (!c.current) {
                            if (c.current = !0, t(e), "Maya" === e) {
                                d.current.style.transform = "scaleX(2)", d.current.style.zIndex = "10", u.current.style.zIndex = "11";
                                let {
                                    width: t
                                } = o.current.getBoundingClientRect();
                                u.current.style.transform = "translate(calc(".concat(.25 * t, "px - 50%),-50%)"), m.current.style.opacity = "0", setTimeout(() => {
                                    u.current.style.transitionDuration = "0.2s", u.current.style.opacity = "0", setTimeout(() => {
                                        a(e)
                                    }, 200)
                                }, 500)
                            } else {
                                h.current.style.transform = "scaleX(2)", h.current.style.zIndex = "10", m.current.style.zIndex = "11";
                                let {
                                    width: t
                                } = o.current.getBoundingClientRect();
                                m.current.style.transform = "translate(calc(50% + ".concat(-(.25 * t), "px),-50%)"), u.current.style.opacity = "0", setTimeout(() => {
                                    m.current.style.transitionDuration = "0.2s", m.current.style.opacity = "0", setTimeout(() => {
                                        a(e)
                                    }, 200)
                                }, 500)
                            }
                        }
                    };
                    return (0, n.jsxs)("div", {
                        className: "w-full h-full absolute",
                        onMouseLeave: () => {
                            "ontouchstart" in window || navigator.maxTouchPoints || c.current || (h.current.style.transform = "scale(1)", u.current.style.transform = "translate(-50%,-50%)", d.current.style.transform = "scale(1)", m.current.style.transform = "translate(50%,-50%)")
                        },
                        ref: o,
                        "data-sentry-component": "ButtonChoiceView",
                        "data-sentry-source-file": "buttonChoiceView.tsx",
                        children: [(0, n.jsx)("div", {
                            ref: d,
                            className: (0, j.A)("w-[50%] transition-transform origin-left duration-500 bg-mayaBase", "flex justify-center items-center cursor-pointer", "absolute h-full left-0"),
                            "data-testid": "maya-button",
                            onMouseEnter: () => {
                                if (c.current || "ontouchstart" in window || navigator.maxTouchPoints) return;
                                d.current.style.transform = "scaleX(1.2)";
                                let {
                                    width: e
                                } = o.current.getBoundingClientRect();
                                u.current.style.transform = "translate(calc(".concat(.05 * e, "px - 50%),-50%)"), h.current.style.transform = "scaleX(0.8)", m.current.style.transform = "translate(calc(50% + ".concat(.05 * e, "px),-50%)")
                            },
                            "aria-label": "Maya",
                            role: "button",
                            tabIndex: 0,
                            onClick: () => p("Maya"),
                            onKeyPress: e => {
                                ("Enter" === e.key || " " === e.key) && p("Maya")
                            },
                            style: {
                                zIndex: "0"
                            }
                        }), (0, n.jsxs)("div", {
                            ref: u,
                            className: "absolute top-[50%] left-[25%] flex gap-[var(--s8)] items-center text-green2 transition-[transform,opacity] origin-left duration-500 pointer-events-none",
                            style: {
                                transform: "translate(-50%,-50%)",
                                zIndex: "1"
                            },
                            children: [(0, n.jsx)(L, {
                                className: "w-[var(--s16)] h-[var(--s16)]",
                                "data-sentry-element": "PhoneCallIcon",
                                "data-sentry-source-file": "buttonChoiceView.tsx"
                            }), (0, n.jsx)("p", {
                                className: "text-sidebar select-none",
                                children: "Maya"
                            })]
                        }), (0, n.jsx)("div", {
                            ref: h,
                            className: (0, j.A)("w-[50%] transition-transform origin-right duration-500 bg-milesBase", "flex justify-center items-center cursor-pointer", "absolute h-full right-0"),
                            onMouseEnter: () => {
                                if (c.current || "ontouchstart" in window || navigator.maxTouchPoints) return;
                                let {
                                    width: e
                                } = o.current.getBoundingClientRect();
                                h.current.style.transform = "scaleX(1.2)", m.current.style.transform = "translate(calc(50% + ".concat(-(.05 * e), "px),-50%)"), d.current.style.transform = "scaleX(0.8)", u.current.style.transform = "translate(calc(".concat(-(.05 * e), "px - 50%),-50%)")
                            },
                            "aria-label": "Miles",
                            role: "button",
                            tabIndex: 0,
                            onClick: () => p("Miles"),
                            onKeyPress: e => {
                                ("Enter" === e.key || " " === e.key) && p("Miles")
                            },
                            style: {
                                zIndex: "0"
                            }
                        }), (0, n.jsxs)("div", {
                            ref: m,
                            className: "absolute top-[50%] right-[25%] flex gap-[var(--s8)] items-center text-green2 pointer-events-none transition-[transform,opacity] origin-right duration-500",
                            style: {
                                transform: "translate(50%,-50%)",
                                zIndex: "1"
                            },
                            children: [(0, n.jsx)(L, {
                                className: "w-[var(--s16)] h-[var(--s16)]",
                                "data-sentry-element": "PhoneCallIcon",
                                "data-sentry-source-file": "buttonChoiceView.tsx"
                            }), (0, n.jsx)("p", {
                                className: "text-sidebar select-none",
                                children: "Miles"
                            })]
                        }), s && (0, n.jsxs)(n.Fragment, {
                            children: [(0, n.jsx)("div", {
                                className: (0, j.A)("w-full h-full absolute z-[98]", "Maya" === i ? "bg-mayaBase" : "bg-milesBase")
                            }), (0, n.jsx)("div", {
                                children: (0, n.jsx)("div", {
                                    className: "w-full h-full absolute z-[99]",
                                    children: (0, n.jsx)(D, {
                                        character: i,
                                        onAnimationEnd: () => {
                                            l && l()
                                        }
                                    }, i)
                                })
                            })]
                        })]
                    })
                };
            var q = function(e) {
                return e[e.Recorded = 0] = "Recorded", e[e.Preparing = 1] = "Preparing", e[e.Prepared = 2] = "Prepared", e[e.Disabled = 3] = "Disabled", e[e.Failed = 4] = "Failed", e
            }({});
            let V = e => {
                let {
                    children: t,
                    disabled: a,
                    ...s
                } = e;
                return (0, n.jsxs)("button", { ...s,
                    disabled: a,
                    className: "py-[var(--s16)] flex-1 text-callbutton text-green2 relative group",
                    "data-sentry-component": "CallEndBottomButton",
                    "data-sentry-source-file": "buttonSignupView.tsx",
                    children: [(0, n.jsx)("span", {
                        className: "relative z-10",
                        children: t
                    }), (0, n.jsx)("span", {
                        className: (0, j.A)("hidden-touch absolute inset-0 z-0 group-disabled:hidden bg-green1 opacity-0 transition-opacity duration-200", !a && "group-hover:opacity-100")
                    })]
                })
            };

            function F(e) {
                let {
                    videoDownloadState: t,
                    videoPreparationProgress: a,
                    onDownloadClip: s,
                    onDownloadNow: i
                } = e, [l, o] = (0, r.useState)(!1);
                return (0, r.useEffect)(() => {
                    if (1 == t) {
                        let e = setTimeout(() => {
                            o(!0)
                        }, 3e3);
                        return () => clearTimeout(e)
                    }
                }, [t]), (0, n.jsx)(n.Fragment, {
                    children: 3 != t ? (0, n.jsxs)(V, {
                        disabled: 1 == t || 4 == t,
                        onClick: 0 == t ? s : i,
                        children: [0 == t && P.downloadClip, 2 == t && P.downloadNow, 4 == t && P.videoFailed, 1 == t && P.preparingClip, 1 == t && l && Math.round(a) + "%"]
                    }) : null
                })
            }
            let W = e => {
                    let {
                        onSkip: t,
                        onDownloadClip: a,
                        onDownloadNow: s,
                        onSubscribe: i,
                        character: l,
                        videoDownloadState: o,
                        videoPreparationProgress: c
                    } = e, d = (0, r.useRef)(null), u = (0, r.useRef)(null), m = (0, r.useRef)(null), [p, f] = (0, r.useState)(!1), [x, v] = (0, r.useState)("");
                    return (0, r.useEffect)(() => {
                        h.Ay.set([m.current], {
                            opacity: 0,
                            autoAlpha: 1
                        }), setTimeout(() => {
                            d.current && (d.current.style.opacity = "1", u.current.style.transform = "scale(1)")
                        }, 100)
                    }, []), (0, n.jsxs)("div", {
                        className: "relative w-full h-full flex flex-col transition-all duration-500",
                        ref: d,
                        style: {
                            opacity: "0"
                        },
                        "data-sentry-component": "ButtonSignupView",
                        "data-sentry-source-file": "buttonSignupView.tsx",
                        children: [(0, n.jsx)("div", {
                            style: {
                                zIndex: "0"
                            },
                            className: (0, j.A)("absolute inset-0", "Maya" === l ? "bg-mayaBase" : "bg-milesBase")
                        }), (0, n.jsx)("div", {
                            ref: u,
                            style: {
                                transform: "scale(0.9)"
                            },
                            className: "w-full h-full px-[var(--s32)] flex items-center flex-1 transition-all duration-500 relative z-10",
                            children: (0, n.jsxs)("div", {
                                className: "w-full relative z-10",
                                children: [(0, n.jsx)("label", {
                                    className: "text-sidebar text-green2",
                                    htmlFor: "email",
                                    children: P.emailLabel
                                }), (0, n.jsxs)("div", {
                                    className: "w-full flex relative mt-[var(--s8)]",
                                    children: [(0, n.jsxs)("div", {
                                        className: (0, j.A)("border-b border-green2 flex gap-[var(--s16)] flex-1 transition-opacity duration-300 delay-100", p && "opacity-0 pointer-events-none"),
                                        children: [(0, n.jsx)("input", {
                                            id: "email",
                                            name: "email",
                                            type: "text",
                                            placeholder: P.emailPlaceholder,
                                            value: x,
                                            onChange: e => v(e.target.value),
                                            className: "placeholder:text-green2/60 pb-[var(--s8)] text-sidebar-light flex-1 outline-none border-none text-green2 bg-[transparent] truncate"
                                        }), (0, n.jsx)("div", {
                                            className: "text-green2 text-sidebar flex gap-[var(--s8)] pb-[var(--s8)]",
                                            children: (0, n.jsx)("button", {
                                                disabled: !x || p,
                                                onClick: async () => {
                                                    await i(x), f(!0)
                                                },
                                                children: P.signup
                                            })
                                        })]
                                    }), (0, n.jsx)("div", {
                                        className: (0, j.A)("absolute top-0 left-0 transition-opacity delay-500 duration-200 text-sidebar-light text-green2 pointer-events-none", p ? "opacity-100" : "opacity-0"),
                                        "aria-hidden": !p,
                                        "aria-label": P.thankYouForSigningUp,
                                        children: P.thankYouForSigningUp
                                    })]
                                })]
                            })
                        }), (0, n.jsxs)("div", {
                            className: "w-full flex relative z-10",
                            children: [(0, n.jsx)(V, {
                                onClick: () => {
                                    m.current.style.zIndex = "20", h.Ay.to(m.current, {
                                        opacity: 1,
                                        duration: .3,
                                        onComplete: () => {
                                            t()
                                        }
                                    })
                                },
                                "data-sentry-element": "CallEndBottomButton",
                                "data-sentry-source-file": "buttonSignupView.tsx",
                                children: p ? P.done : P.skip
                            }), (0, n.jsx)(F, {
                                videoDownloadState: o,
                                videoPreparationProgress: c,
                                onDownloadClip: a,
                                onDownloadNow: s,
                                "data-sentry-element": "VideoDownloadButton",
                                "data-sentry-source-file": "buttonSignupView.tsx"
                            })]
                        }), (0, n.jsx)("div", {
                            ref: m,
                            style: {
                                zIndex: "-1"
                            },
                            className: (0, j.A)("absolute inset-0 invisible", "Maya" === l ? "bg-mayaBase" : "bg-milesBase")
                        })]
                    })
                },
                G = r.forwardRef((e, t) => {
                    let {
                        character: a,
                        delay: s,
                        children: i
                    } = e, l = (0, r.useRef)(null), o = e => {
                        l.current && h.Ay.to(l.current, {
                            opacity: 0,
                            duration: .3,
                            onComplete: e
                        })
                    };
                    return (0, r.useImperativeHandle)(t, () => ({
                        fadeOut: o
                    })), (0, n.jsx)("div", {
                        className: (0, j.A)("absolute z-50 w-full h-full flex justify-center items-center p-[var(--s16)]", "Maya" === a ? "bg-mayaBase" : "bg-milesBase"),
                        children: (0, n.jsx)("div", {
                            ref: l,
                            children: (0, n.jsx)("p", {
                                className: "text-sidebar text-center opacity-0 text-green2",
                                style: {
                                    animation: "fadeIn 0.3s ".concat(s ? s + "s" : ".2s", " forwards")
                                },
                                children: i
                            })
                        })
                    })
                });
            G.displayName = "ButtonWarningView";
            var H = a(3889);
            let U = e => {
                    var t, a, s, r;
                    let {
                        visible: i
                    } = e, {
                        devices: l,
                        error: o,
                        isLoading: c
                    } = (0, H.useMediaDevices)();
                    if (c || o) return null;
                    let d = null === (a = l.find(e => "audioinput" === e.kind)) || void 0 === a ? void 0 : null === (t = a.label) || void 0 === t ? void 0 : t.replace("Default - ", "").trim(),
                        u = null === (r = l.find(e => "audiooutput" === e.kind)) || void 0 === r ? void 0 : null === (s = r.label) || void 0 === s ? void 0 : s.replace("Default - ", "").trim();
                    ("Unknown Device" === d || "Default" === d) && (d = null), ("Unknown Device" === u || "Default" === u) && (u = null);
                    let h = d || u;
                    return (0, n.jsxs)("div", {
                        className: (0, j.A)("flex flex-col md:flex-row items-start md:gap-[var(--s12)] md:items-center transition-opacity duration-300 select-none", i && h ? "opacity-100 delay-200" : "opacity-0"),
                        "data-sentry-component": "CallButtonIODevices",
                        "data-sentry-source-file": "callButtonIOdevices.tsx",
                        children: [d && (0, n.jsx)("div", {
                            children: d
                        }), d && u && (0, n.jsx)("div", {
                            className: "hidden md:block h-[var(--s12)] w-[1px] bg-tertiary"
                        }), u && (0, n.jsx)("div", {
                            children: u
                        }), u && !d && (0, n.jsx)("div", {
                            className: "hidden md:block h-full w-[1px] bg-tertiary"
                        })]
                    })
                },
                X = () => (0, n.jsxs)("span", {
                    className: "flex gap-[var(--s2)]",
                    "data-sentry-component": "Spinner",
                    "data-sentry-source-file": "spinner.tsx",
                    children: [(0, n.jsx)("span", {
                        className: "h-[var(--s6)] w-[var(--s6)] rounded-full bg-green2 block",
                        style: {
                            animation: "pulse 1.5s infinite"
                        }
                    }), (0, n.jsx)("span", {
                        className: "h-[var(--s6)] w-[var(--s6)] rounded-full bg-green2 block",
                        style: {
                            animation: "pulse 1.5s .3s infinite"
                        }
                    }), (0, n.jsx)("span", {
                        className: "h-[var(--s6)] w-[var(--s6)] rounded-full bg-green2 block",
                        style: {
                            animation: "pulse 1.5s .6s infinite"
                        }
                    }), (0, n.jsx)("style", {
                        children: "\n                @keyframes pulse {\n                    0%{\n                        opacity: 0.2;\n                    }\n                    50%{\n                        opacity: 1;\n                    }\n                    100%{\n                        opacity: 0.2;\n                    }\n                }\n\n            "
                    })]
                });
            var Q = a(6873),
                J = a(7278),
                K = a(4499),
                Y = a(6909),
                Z = a(3591),
                $ = a(8592);

            function ee(e) {
                let {
                    onSkip: t,
                    character: a,
                    onDownloadClip: s,
                    onDownloadNow: i,
                    videoDownloadState: l,
                    videoPreparationProgress: o,
                    callId: c
                } = e, d = r.useRef(null), u = r.useRef(null), {
                    isLoggedInUser: m
                } = (0, J.n)(), p = r.useCallback(() => {
                    u.current.style.zIndex = "20", h.Ay.to(u.current, {
                        opacity: 1,
                        duration: .3,
                        onComplete: () => {
                            t()
                        }
                    })
                }, [t]);
                return (0, n.jsxs)("div", {
                    className: (0, j.A)("absolute w-full h-full flex flex-col", "Maya" === a ? "bg-mayaBase" : "bg-milesBase"),
                    ref: d,
                    "data-sentry-component": "ButtonPostCallView",
                    "data-sentry-source-file": "buttonPostCallView.tsx",
                    children: [(0, n.jsxs)("div", {
                        className: "px-[var(--s32px)] pt-[var(--s36px)] flex flex-col flex-1",
                        children: [(0, n.jsx)("div", {
                            className: "flex-1 font-weight-600",
                            children: m ? (0, n.jsxs)("h1", {
                                className: "text-research-h1",
                                children: ["Thank you for", (0, n.jsx)("br", {}), " trying our demo"]
                            }) : (0, n.jsxs)("h1", {
                                className: "text-research-h1",
                                children: ["Log in for ", (0, n.jsx)("br", {}), "longer calls"]
                            })
                        }), m ? (0, n.jsx)(es, {
                            character: a,
                            callId: c
                        }) : (0, n.jsx)(et, {}), (0, n.jsx)("div", {
                            className: "w-full mt-[var(--s20px)] line"
                        })]
                    }), (0, n.jsxs)("div", {
                        className: "w-full flex relative z-10",
                        children: [(0, n.jsx)(V, {
                            onClick: p,
                            "data-sentry-element": "CallEndBottomButton",
                            "data-sentry-source-file": "buttonPostCallView.tsx",
                            children: P.skip
                        }), (0, n.jsx)(F, {
                            videoDownloadState: l,
                            videoPreparationProgress: o,
                            onDownloadClip: s,
                            onDownloadNow: i,
                            "data-sentry-element": "VideoDownloadButton",
                            "data-sentry-source-file": "buttonPostCallView.tsx"
                        })]
                    }), (0, n.jsx)("div", {
                        ref: u,
                        style: {
                            zIndex: "-1"
                        },
                        className: (0, j.A)("absolute inset-0 invisible", "Maya" === a ? "bg-mayaBase" : "bg-milesBase")
                    })]
                })
            }

            function et() {
                let e = r.useCallback(async () => {
                    J.n.getState().signInWithGoogle()
                }, []);
                return (0, n.jsx)(Z.A, {
                    icon: (0, n.jsx)($.A, {
                        fillColor: "#76796A"
                    }),
                    text: "Continue with Google",
                    onClick: e,
                    variant: "brand",
                    "data-sentry-element": "ElevatedButton",
                    "data-sentry-component": "GoogleLoginButton",
                    "data-sentry-source-file": "buttonPostCallView.tsx"
                })
            }
            let ea = "https://form.typeform.com/to/Qfav4vYS";

            function es(e) {
                let {
                    character: t,
                    callId: a
                } = e, s = r.useCallback(() => {
                    let e = null != a ? "".concat(ea, "#call_id=").concat(a) : ea;
                    window.open(e, "_blank")
                }, [a]);
                return (0, n.jsx)(Z.A, {
                    text: P.feedbackButton("Maya" === t ? P.maya : P.miles),
                    onClick: s,
                    variant: "brand",
                    "data-sentry-element": "ElevatedButton",
                    "data-sentry-component": "FeedbackButton",
                    "data-sentry-source-file": "buttonPostCallView.tsx"
                })
            }
            var en = a(1048),
                er = a(9728),
                ei = a(9945);
            h.os.registerPlugin(p.Draggable);
            let el = null,
                eo = {
                    a: "Maya",
                    b: "Maya-Alpha"
                },
                ec = {
                    ringtone: {
                        ringtone: "https://storage.googleapis.com/sesame-dev-public/audio/ringtone2.mp3",
                        ringtoneMaxDurationMs: 3e3,
                        inputWarmupMs: 600
                    },
                    no_delay: {
                        inputWarmupMs: 0
                    },
                    none: {
                        inputWarmupMs: 3e3
                    }
                },
                ed = "https://storage.googleapis.com/sesame-dev-public/audio/set_14_12_connect_07.mp3",
                eu = "https://storage.googleapis.com/sesame-dev-public/audio/set_14_12_disconnect.mp3";
            class eh {
                constructor(e, t, a, s) {
                    this.blob = e, this.extension = t, this.useSharingAPI = a, this.targetName = s
                }
            }
            let em = (e, t) => e instanceof d.us ? P.serviceUnavailable(t) : e instanceof d.Py ? P.micInputNotDetected : e instanceof d.GO ? P.callDropped : e instanceof d.$h ? P.backgroundCallEnded : P.unknownError(t),
                ep = e => {
                    let {
                        sesameLogo: t,
                        mayaLogo: s,
                        milesLogo: i,
                        textScale: l
                    } = e, o = (0, r.useRef)(!1), c = (0, r.useRef)(null), p = (0, r.useRef)(null), y = (0, r.useRef)(!0), b = (0, r.useRef)(!1), [N, _] = (0, r.useState)(null), [k, C] = (0, r.useState)(null), [S, A] = (0, r.useState)(Date.now()), [M, E] = (0, r.useState)(!1), [R, z] = (0, r.useState)(d.iP.DISCONNECTED), [I, B] = (0, r.useState)(0), [L, D] = (0, r.useState)(null), [V, F] = (0, r.useState)(null), {
                        record: H,
                        stopRecord: J,
                        createVideo: Y,
                        videoFinalizing: Z,
                        videoDownloadable: $,
                        setAudio: et
                    } = function(e) {
                        let [t, a] = (0, r.useState)(!1), s = (0, r.useMemo)(() => new w(e), []), [n, i] = (0, r.useState)(!1), [l, o] = (0, r.useState)(!1), [c, d] = (0, r.useState)(null);
                        return {
                            createVideo: async e => {
                                if (c) return c;
                                if (!t) {
                                    console.warn("No recording to convert");
                                    return
                                }
                                for (o(!0);;) {
                                    let t = await s.finalizeVideo(e);
                                    if (t) {
                                        let {
                                            blob: e,
                                            extension: a
                                        } = t, s = "sesame_call_".concat(Date.now(), ".").concat(a);
                                        return o(!1), d({
                                            blob: e,
                                            filename: s
                                        }), {
                                            blob: e,
                                            filename: s
                                        }
                                    }
                                    await new Promise(e => setTimeout(e, 200))
                                }
                            },
                            record: function(e) {
                                let t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {};
                                i(!0), a(!1), d(null), o(!1), s.record(e, t)
                            },
                            recording: n,
                            setAudio: function(e) {
                                s.setAudio(e)
                            },
                            stopRecord: function() {
                                let e = s.stop();
                                i(!1), a(e)
                            },
                            videoDownloadable: t,
                            videoFinalizing: l
                        }
                    }(g.c), [ea, es] = (0, r.useState)(0), er = (0, r.useRef)(null), {
                        mayaIsInitialized: ep,
                        setMayaIsConnected: ex,
                        setMayaIsInitialized: ev
                    } = (0, f.P)(e => ({
                        mayaIsInitialized: e.mayaIsInitialized,
                        setMayaIsConnected: e.setMayaIsConnected,
                        setMayaIsInitialized: e.setMayaIsInitialized
                    })), [eg, ey] = (0, r.useState)(!1), eb = (0, r.useRef)(!1), [ew, ej] = (0, r.useState)(!1), [eN, e_] = (0, r.useState)(null), [ek, eC] = (0, r.useState)(q.Disabled), [eS, eA] = (0, r.useState)(0), [eM, eE] = (0, r.useState)(null), eR = (0, r.useRef)(null), ez = (0, r.useRef)(null), eP = (0, r.useRef)(null), eT = (0, r.useRef)(null), eI = (0, m.useRouter)();
                    (0, r.useEffect)(() => {
                        if (!eb.current || !$) {
                            eC(q.Disabled);
                            return
                        }
                        eC(q.Recorded)
                    }, [$]);
                    let {
                        webClient: eB,
                        maybeInitClient: eL
                    } = r.useContext(Q.DS), eD = function(e) {
                        let t = r.useRef(null),
                            a = r.useCallback(() => {
                                if (null !== e) return Promise.resolve(e);
                                if (null === t.current) {
                                    let e;
                                    t.current = {
                                        promise: new Promise(t => {
                                            e = t
                                        }),
                                        resolve: e
                                    }
                                }
                                return t.current.promise
                            }, [e]),
                            s = (0, en.Z)(e);
                        return r.useEffect(() => {
                            null !== e && null !== t.current && t.current.resolve(e)
                        }, [e]), r.useEffect(() => {
                            null !== s && null === e && (t.current = null)
                        }, [s, e]), a
                    }(eB);
                    (0, r.useEffect)(() => {
                        er.current = (async () => {
                            let e = eD(),
                                t = await e;
                            return eb.current = t.featureFlagManager.isEnabled("video_download"), t
                        })()
                    }, [eD]), (0, x.Q)(e => {
                        let {
                            width: t
                        } = e;
                        ey(t), eF()
                    }, {
                        fireOnInitialRender: !0
                    }), (0, r.useEffect)(() => {
                        if (ep && window.glCanvas && !o.current) {
                            o.current = !0;
                            let e = window.glCanvas;
                            c.current.append(e)
                        }
                    }, [ep]), (0, r.useEffect)(() => {
                        if (!ep || window.glCanvas) return;
                        let e = document.createElement("canvas");
                        e.id = "dat-canvas", e.style.width = "100%", e.style.height = "100%", e.classList.add("initialized"), window.glCanvas = e, c.current.append(e), o.current = !0, null == (el = a(5761).A) || el.init({
                            assetRoot: "public/",
                            canvas: e,
                            logo: t.url,
                            nameImages: {
                                maya: s.url,
                                miles: i.url
                            },
                            contextLossCallback: () => {
                                eB.analyticsManager.track(new d.pM("WEBGL_CONTEXT_LOSS", "WebGL context lost"), !0), C(P.webgl_context_lost), eb.current = !1, window.app && (window.app.disconnect(0), window.app.pause()), window.app = null, el = null
                            }
                        }), (async () => {
                            await (null == el ? void 0 : el.preload()), await (null == el ? void 0 : el.start()), window.app = el, eF()
                        })().catch(e => {
                            el = null, window.app = null, C(P.webgl_unavailable), eb.current = !1;
                            let t = e instanceof Error ? JSON.stringify({
                                message: e.message,
                                name: e.name,
                                stack: e.stack,
                                cause: e.cause
                            }) : JSON.stringify(e);
                            eB.analyticsManager.track(new d.pM("WEBGL_ERROR", t), !0)
                        })
                    }, [ep]), (0, r.useEffect)(() => {
                        eF()
                    }, [eg]), (0, r.useEffect)(() => {
                        var e, t;
                        return null == eB || null === (e = eB.notification) || void 0 === e || e.precacheAudio(ed), null == eB || null === (t = eB.notification) || void 0 === t || t.precacheAudio(eu), () => {
                            var e;
                            (null == eB ? void 0 : null === (e = eB.getSession()) || void 0 === e ? void 0 : e.isCallActive()) && (window.app && (window.app.disconnect(0), window.app.pause()), eY())
                        }
                    }, [eB]);
                    let eO = (0, K.A)(),
                        eq = r.useCallback(() => {
                            eO ? es(4) : es(3)
                        }, [eO]);
                    (0, r.useEffect)(() => {
                        k !== P.warnSafari175 && k !== P.webgl_context_lost && k !== P.webgl_unavailable && (I > (null == eB ? void 0 : eB.getPoorRttThresholdMs()) ? (C(P.poorConnection), A(Date.now())) : k && Date.now() - S > 5e3 && C(null))
                    }, [I]);
                    let eV = e => {
                            let t = () => {
                                let {
                                    input: a,
                                    output: s
                                } = e.getFrequencies();
                                null == el || el.audioFeed(a, s), e.isCallActive() && requestAnimationFrame(t)
                            };
                            t()
                        },
                        eF = () => {
                            if (!eg || !el || !el.preloaded || !c.current) return;
                            let {
                                width: e,
                                height: a
                            } = c.current.getBoundingClientRect();
                            window.glCanvsScale = 1;
                            let s = window.glCanvsScale;
                            if (window.glCanvas.style.transform = "scale(".concat(1 / s, ")"), null == el || el.resize(e * s, a * s), el && !y.current) {
                                let {
                                    height: e
                                } = p.current.getBoundingClientRect();
                                el.zoom = e * s * .5
                            }
                            let {
                                height: n
                            } = eT.current.getBoundingClientRect(), r = (a - n) * .5 * s, i = r * l, o = r * (1 - l) * .5, d = t.width / t.height;
                            null == el || el.setTextOption({
                                position: {
                                    x: e - i * d * .5 - o,
                                    y: o + .5 * i
                                },
                                scale: i
                            }), null == el || el.setNameTextOption({
                                scale: i
                            }), eW()
                        },
                        eW = e => {
                            if (!window.app) return;
                            let t = window.glCanvsScale || 1,
                                {
                                    height: a
                                } = c.current.getBoundingClientRect(),
                                {
                                    height: s
                                } = eT.current.getBoundingClientRect(),
                                n = (a - s) * .5 * t,
                                r = n * (1 - l) * .5,
                                i = n * l * ("Maya" === e ? 1.2 : 1);
                            null == el || el.setNameTextOption({
                                position: {
                                    x: (.5 * i + r + (a - s) * .25) * t,
                                    y: r + .5 * i
                                },
                                scale: i
                            })
                        },
                        eG = async () => {
                            let {
                                height: e
                            } = p.current.getBoundingClientRect();
                            y.current = !0;
                            let t = .5 * e;
                            return new Promise(e => {
                                el ? h.os.to(el, {
                                    zoom: t,
                                    duration: .7,
                                    onComplete: () => {
                                        y.current = !1, e()
                                    }
                                }) : (y.current = !1, e())
                            })
                        },
                        eH = async () => {
                            let {
                                width: e
                            } = c.current.getBoundingClientRect();
                            return new Promise(t => {
                                el ? h.os.to(el, {
                                    zoom: .75 * e,
                                    duration: .7,
                                    onComplete: () => {
                                        y.current = !0, t()
                                    }
                                }) : (y.current = !0, t())
                            })
                        },
                        eU = e => {
                            if ("visible" === document.visibilityState) e();
                            else {
                                let t = () => {
                                    "visible" === document.visibilityState && (e(), document.removeEventListener("visibilitychange", t))
                                };
                                document.addEventListener("visibilitychange", t)
                            }
                        },
                        eX = (e, t, a) => {
                            var s;
                            b.current || (b.current = !0, null === (s = eP.current) || void 0 === s || s.onClickEndCall(async () => {
                                var s, n, r;
                                null === (s = window.app) || void 0 === s || s.play(), null === (n = window.app) || void 0 === n || n.disconnect(.3), await eH(), null === (r = window.app) || void 0 === r || r.pause(), e instanceof d.w2 ? (E(!0), eq()) : (_(em(e, t)), (e instanceof d.Py || e instanceof d.hm) && a.stopCall(), setTimeout(() => {
                                    var e;
                                    null === (e = ez.current) || void 0 === e || e.fadeOut(() => {
                                        _(null), ej(!0), es(0)
                                    })
                                }, 2e3))
                            }))
                        },
                        eQ = e => {
                            _(e || null), e && setTimeout(() => {
                                var e;
                                null === (e = ez.current) || void 0 === e || e.fadeOut(() => {
                                    var e;
                                    _(null), ej(!0), es(0), null === (e = window.app) || void 0 === e || e.pause()
                                })
                            }, 2e3)
                        },
                        eJ = (e, t) => {
                            e instanceof d.Py || e instanceof d.hm ? t.analyticsManager.track(new d.J_(e.code, e.message, e.details), !0) : e instanceof d.p3 ? t.analyticsManager.track(new d.cJ(e.code, e.message, e.details), !0) : t.analyticsManager.track(new d.cJ("unknown", e.message, e.stack), !0)
                        },
                        eK = async e => {
                            var t, a, s, n;
                            let r;
                            if (eL(), null != er.current && (r = await er.current), null == r) return;
                            (0, v.sendGAEvent)("event", "start_call", {
                                character: e
                            });
                            let i = null !== (s = ec[null === (t = eI.query.call_start) || void 0 === t ? void 0 : t.toLowerCase()]) && void 0 !== s ? s : ec.none,
                                l = null === (a = eI.query.preset) || void 0 === a ? void 0 : a.toLowerCase(),
                                o = null !== (n = eo[l]) && void 0 !== n ? n : l;
                            _(null), eA(0), eE(null), b.current = !1, E(!1);
                            try {
                                if (z(d.iP.CONNECTING), window.app) {
                                    let {
                                        width: t
                                    } = c.current.getBoundingClientRect();
                                    window.app.setPreset(e.toLocaleLowerCase()), window.app.play(), window.app.zoom = t, eW(e)
                                }
                                let t = await r.startCall({
                                    character: e,
                                    preset: o,
                                    onError: t => {
                                        if (t instanceof d.mn) {
                                            C(P.warnSafari175);
                                            return
                                        }
                                        eJ(t, r), eU(() => {
                                            eX(t, e, r)
                                        })
                                    },
                                    onConnectionQualityChange: B,
                                    onCallStateChange: async t => {
                                        z(t);
                                        let {
                                            audioSession: a
                                        } = navigator;
                                        if (t === d.iP.CONNECTED) {
                                            var s;
                                            let t = null === (s = r.getSession()) || void 0 === s ? void 0 : s.getCallId();
                                            null != t && F(t), a && (a.type = "play-and-record"), navigator.mediaSession && (navigator.mediaSession.metadata = new MediaMetadata({
                                                title: e,
                                                artist: "Sesame"
                                            })), e_(null), eb.current && window.glCanvas && H(window.glCanvas, {
                                                frameRate: 60,
                                                maxDurationS: r.featureFlagManager.getConfig(d.mC.VIDEO_DOWNLOAD_CONFIG).max_duration_s
                                            }), ex(!0)
                                        } else navigator.mediaSession && (navigator.mediaSession.metadata = null), a && (a.type = "auto"), ex(!1)
                                    },
                                    onRawRecordingComplete: e => {
                                        J(), et(e)
                                    },
                                    audioOptions: { ...i,
                                        connectedChime: ed,
                                        disconnectedChime: eu,
                                        enableRecording: !1
                                    },
                                    chimeTask: async () => {
                                        var e;
                                        z(d.iP.CONNECTED), es(2), await eG(), null === (e = window.app) || void 0 === e || e.connect()
                                    }
                                });
                                eV(t)
                            } catch (t) {
                                z(d.iP.DISCONNECTED), r.analyticsManager.track(new d.J_(t.code, t.message, t.details), !0), eU(() => {
                                    eQ(em(t, e))
                                })
                            }
                        },
                        eY = async () => {
                            (0, v.sendGAEvent)("event", "stop_call", {}), await eB.stopCall({
                                chimeTask: async () => {
                                    var e, t;
                                    null === (e = window.app) || void 0 === e || e.disconnect(.3), await eH(), null === (t = window.app) || void 0 === t || t.pause(), eq()
                                }
                            })
                        },
                        eZ = async e => {
                            let t = null == eB ? void 0 : await eB.getSession();
                            null != t && t.isCallActive() ? await eY() : await eK(e)
                        },
                        e$ = async () => {
                            var e;
                            null === (e = eB.getSession()) || void 0 === e || e.setMuteOutput(!0), eY()
                        },
                        e0 = e => {
                            eA(Math.max(0, Math.min(100, Math.round(100 * e))))
                        },
                        e1 = async () => {
                            let e, t;
                            eB.analyticsManager.track(new d.cT(!1), !0), eC(q.Preparing);
                            let a = new Date().valueOf();
                            try {
                                ({
                                    blob: e,
                                    filename: t
                                } = await Y(e0))
                            } catch (e) {
                                console.error("Error preparing video for download", e), eC(q.Failed);
                                return
                            }
                            let s = new Date().valueOf() - a,
                                n = t.split(".").pop();
                            eB.analyticsManager.track(new d.cW(e.size, n, s), !0);
                            let r = new Date().toLocaleDateString("sv") + "_" + new Date().toLocaleTimeString("sv").replace(/:/g, "-"),
                                i = "sesame_call_".concat(r, ".").concat(n),
                                l = 1048576 * eB.featureFlagManager.getConfig(d.mC.VIDEO_DOWNLOAD_CONFIG).max_share_size_mb;
                            console.log("Max file size for navigator.share configured as ".concat(l, " bytes."));
                            let o = "mobile" === u.getParser(window.navigator.userAgent).getPlatformType() && navigator.share && e.size < l;
                            eE(new eh(e, n, o, i)), eC(q.Prepared)
                        };
                    (0, r.useEffect)(() => {
                        null != eM && e2(!1)
                    }, [eM]);
                    let e2 = async function() {
                            let e = !(arguments.length > 0) || void 0 === arguments[0] || arguments[0];
                            if (e && eB.analyticsManager.track(new d.cT(!0), !0), null == eM) {
                                console.error("Unexpected state: preparedDownload not set."), eC(q.Failed);
                                return
                            }
                            let t = !1;
                            if (eM.useSharingAPI) {
                                eB.analyticsManager.track(new d.Ay(eM.blob.size, eM.extension), !0);
                                try {
                                    await navigator.share({
                                        files: [new File([eM.blob], eM.targetName, {
                                            type: eM.blob.type
                                        })]
                                    }), t = !0, eB.analyticsManager.track(new d.yv(eM.blob.size, eM.extension), !0)
                                } catch (e) {
                                    e.code === DOMException.ABORT_ERR ? (t = !0, eB.analyticsManager.track(new d.Xe(eM.blob.size, eM.extension), !0)) : eB.analyticsManager.track(new d.s5(eM.blob.size, eM.extension, String(e)), !0)
                                }
                            }
                            if (!t) {
                                eB.analyticsManager.track(new d.ab(eM.blob.size, eM.extension), !0);
                                try {
                                    let e = URL.createObjectURL(eM.blob),
                                        t = document.createElement("a");
                                    t.href = e, t.download = eM.targetName, document.body.appendChild(t), t.click(), document.body.removeChild(t), URL.revokeObjectURL(e)
                                } catch (e) {
                                    console.error("Error downloading video", e), eC(q.Failed)
                                }
                            }
                        },
                        e4 = async e => {
                            (0, ei.A)(e, eB)
                        },
                        e6 = r.useCallback(() => {
                            ej(!0), E(!1), es(0)
                        }, []);
                    return (0, n.jsx)(n.Fragment, {
                        children: (0, n.jsxs)("div", {
                            className: "flex flex-col gap-[var(--s16)]",
                            children: [(0, n.jsxs)("div", {
                                ref: eT,
                                className: (0, j.A)("border rounded-radius2 border-green4 w-full relative overflow-hidden", "h-[21rem]", 1 === ea || 0 === ea || "prompt" === eN || "denied" === eN ? "Maya" === L ? "bg-mayaBase" : "Miles" === L ? "bg-milesBase" : "bg-[transparent]" : "bg-[transparent]"),
                                children: [(0, n.jsxs)("div", {
                                    className: (0, j.A)("absolute w-full h-full z-0 top-0"),
                                    children: [(0, n.jsx)("span", {
                                        ref: p,
                                        className: "aspect-square h-[var(--s90)] md:h-[6rem] absolute translate-x-[-50%] translate-y-[-50%] top-[50%] left-[50%] rounded-full z-10"
                                    }), (0, n.jsx)("div", {
                                        ref: c,
                                        className: "w-full h-[120%] z-0 top-[50%] translate-y-[-50%] absolute"
                                    })]
                                }), 0 === ea && (0, n.jsx)(O, {
                                    onClickChoice: async e => {
                                        D(e), ev(!0)
                                    },
                                    onOutroEnd: async e => {
                                        let t = await navigator.permissions.query({
                                            name: "microphone"
                                        });
                                        if ("prompt" === t.state) {
                                            e_("prompt");
                                            try {
                                                (await navigator.mediaDevices.getUserMedia({
                                                    audio: !0
                                                })).getTracks().forEach(e => e.stop()), eR.current.fadeOut(() => {
                                                    eZ(e), e_("granted")
                                                })
                                            } catch (e) {
                                                eR.current ? eR.current.fadeOut(() => {
                                                    e_("denied")
                                                }) : e_("denied")
                                            }
                                        } else "granted" === t.state ? (e_("granted"), eZ(e)) : "denied" === t.state && e_("denied")
                                    },
                                    animateIntro: ew,
                                    character: L,
                                    onIntroEnd: () => {
                                        ej(!1)
                                    }
                                }, ew ? "withIntro" : "withoutIntro"), 2 === ea && (0, n.jsx)(T, {
                                    ref: eP,
                                    callWarning: k,
                                    onEndCall: () => {
                                        e$()
                                    },
                                    onMute: () => {
                                        var e;
                                        return null == eB ? void 0 : null === (e = eB.getSession()) || void 0 === e ? void 0 : e.setMuteInput(!0)
                                    },
                                    onUnmute: () => {
                                        var e;
                                        return null == eB ? void 0 : null === (e = eB.getSession()) || void 0 === e ? void 0 : e.setMuteInput(!1)
                                    },
                                    callIsActive: R === d.iP.CONNECTED,
                                    character: L
                                }), 0 === ea && "prompt" === eN && (0, n.jsx)(G, {
                                    character: L,
                                    ref: eR,
                                    children: P.microphoneAccessPrompt(L)
                                }), 0 === ea && "denied" === eN && (0, n.jsx)(G, {
                                    character: L,
                                    children: P.microphoneAccessDenied
                                }), 0 === ea && R === d.iP.CONNECTING && (0, n.jsx)(G, {
                                    character: L,
                                    delay: .7,
                                    children: (0, n.jsxs)("span", {
                                        className: "flex gap-[var(--s12)] items-center",
                                        children: [(0, n.jsx)("span", {
                                            className: "block",
                                            children: P.connecting(L)
                                        }), (0, n.jsx)(X, {})]
                                    })
                                }), 3 === ea && (0, n.jsx)(W, {
                                    character: L,
                                    onSkip: e6,
                                    onDownloadClip: e1,
                                    onDownloadNow: e2,
                                    onSubscribe: e4,
                                    videoDownloadState: ek,
                                    videoPreparationProgress: eS
                                }), 4 === ea && (0, n.jsx)(ee, {
                                    onSkip: e6,
                                    character: L,
                                    onDownloadClip: e1,
                                    onDownloadNow: e2,
                                    videoDownloadState: ek,
                                    videoPreparationProgress: eS,
                                    callId: null != V ? V : void 0
                                }), N && (0, n.jsx)(G, {
                                    ref: ez,
                                    character: L,
                                    delay: .2,
                                    children: N
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "text-sidebar-light text-tertiary shrink-0  min-h-[var(--s32)] relative",
                                children: [(0, n.jsx)(U, {
                                    visible: 2 === ea,
                                    "data-sentry-element": "CallButtonIODevices",
                                    "data-sentry-source-file": "visualizer.tsx"
                                }), (0, n.jsxs)("p", {
                                    className: (0, j.A)("absolute top-0 left-0 transition-opacity select-none", 0 === ea ? "opacity-100 duration-300" : "opacity-0 duration-200"),
                                    children: [P.pressToStart, (0, n.jsx)(ef, {
                                        "data-sentry-element": "LoginText",
                                        "data-sentry-source-file": "visualizer.tsx"
                                    })]
                                }), (0, n.jsx)("p", {
                                    className: (0, j.A)("absolute top-0 left-0 transition-opacity select-none pointer-events-none", 3 === ea && M ? "opacity-100 duration-300" : "opacity-0 duration-200"),
                                    children: P.maxDurationMessage(L)
                                })]
                            })]
                        })
                    })
                };

            function ef() {
                let e = (0, K.A)(),
                    {
                        isLoggedInUser: t,
                        isLoading: a,
                        user: s
                    } = (0, J.n)(),
                    r = (null == s ? void 0 : s.email) != null ? P.loggedInVisualizerSubtextWithEmail(s.email) : P.loggedInVisualizerSubtextDefault;
                return e ? !e || t || a ? (0, n.jsxs)(n.Fragment, {
                    children: [".\xa0", r]
                }) : (0, n.jsxs)(n.Fragment, {
                    children: [".\xa0", (0, n.jsxs)(er.A, {
                        href: Y.A.login,
                        className: "underline",
                        children: ["Log in", " "]
                    }), " ", "for calls up to 30 minutes."]
                }) : null
            }
            var ex = a(260),
                ev = a(1106),
                eg = a.n(ev);

            function ey(e) {
                return (ey = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function(e) {
                    return typeof e
                } : function(e) {
                    return e && "function" == typeof Symbol && e.constructor === Symbol && e !== Symbol.prototype ? "symbol" : typeof e
                })(e)
            }

            function eb() {
                return (eb = Object.assign ? Object.assign.bind() : function(e) {
                    for (var t = 1; t < arguments.length; t++) {
                        var a = arguments[t];
                        for (var s in a)({}).hasOwnProperty.call(a, s) && (e[s] = a[s])
                    }
                    return e
                }).apply(null, arguments)
            }

            function ew(e, t, a) {
                var s;
                return (s = function(e, t) {
                    if ("object" != ey(e) || !e) return e;
                    var a = e[Symbol.toPrimitive];
                    if (void 0 !== a) {
                        var s = a.call(e, t || "default");
                        if ("object" != ey(s)) return s;
                        throw TypeError("@@toPrimitive must return a primitive value.")
                    }
                    return ("string" === t ? String : Number)(e)
                }(t, "string"), (t = "symbol" == ey(s) ? s : s + "") in e) ? Object.defineProperty(e, t, {
                    value: a,
                    enumerable: !0,
                    configurable: !0,
                    writable: !0
                }) : e[t] = a, e
            }
            let ej = function(e) {
                return r.createElement("svg", eb({
                    xmlns: "http://www.w3.org/2000/svg",
                    width: 13,
                    height: 16,
                    fill: "none"
                }, e), r.createElement("path", {
                    fill: "#111",
                    d: "M6.847.757c.496 0 .831.343.831.846v9.472l-.06 1.64 2.013-2.242 1.73-1.709a.86.86 0 0 1 .596-.244c.457 0 .793.351.793.816 0 .221-.084.42-.26.603l-5.025 5.033a.88.88 0 0 1-.618.267.88.88 0 0 1-.618-.267L1.204 9.939a.85.85 0 0 1-.26-.603c0-.465.344-.816.801-.816.23 0 .443.1.588.244l1.73 1.709 2.014 2.25-.061-1.648V1.603c0-.503.343-.846.831-.846",
                    style: ew(ew({
                        fill: "#111"
                    }, "fill", "color(display-p3 .0667 .0667 .0667)"), "fillOpacity", 1)
                }))
            };
            var eN = a(6728);

            function e_() {
                let e = (0, K.A)();
                return !0 === e ? (0, n.jsx)(ek, {}) : !1 === e ? (0, n.jsx)(eC, {}) : null
            }

            function ek() {
                return (0, n.jsxs)("p", {
                    className: "text-caption-sm text-tertiary select-none ",
                    "data-sentry-component": "VisualizerSubtextLoginEnabled",
                    "data-sentry-source-file": "VisualizerSubtext.tsx",
                    children: ["1. Microphone permission is required. \xa0 2. Calls are recorded and may be used to improve Maya and Miles. \xa0 3. By using this demo, you are agreeing to our", " ", (0, n.jsxs)(er.A, {
                        href: Y.A.terms,
                        className: "underline",
                        "data-sentry-element": "Link",
                        "data-sentry-source-file": "VisualizerSubtext.tsx",
                        children: ["Terms of Use", " "]
                    }), " ", "and", " ", (0, n.jsx)(er.A, {
                        href: Y.A.privacy,
                        className: "underline",
                        "data-sentry-element": "Link",
                        "data-sentry-source-file": "VisualizerSubtext.tsx",
                        children: "Privacy Policy"
                    }), ". \xa0 4. We recommend using Chrome (Audio quality may be degraded in iOS/Safari 17.5). \xa0 5. Demo not intended for users in EEA/UK/Switzerland."]
                })
            }

            function eC() {
                return (0, n.jsxs)("p", {
                    className: "text-caption-sm text-tertiary select-none ",
                    "data-sentry-component": "VisualizerSubtextLoginDisabled",
                    "data-sentry-source-file": "VisualizerSubtext.tsx",
                    children: ["1. Microphone permission is required. 2. Calls are recorded for quality review but not used for ML training and are deleted within 30 days. 3. By using this demo, you are agreeing to our", " ", (0, n.jsxs)(er.A, {
                        href: Y.A.terms,
                        className: "underline",
                        "data-sentry-element": "Link",
                        "data-sentry-source-file": "VisualizerSubtext.tsx",
                        children: ["Terms of Use", " "]
                    }), " ", "and", " ", (0, n.jsx)(er.A, {
                        href: Y.A.privacy,
                        className: "underline",
                        "data-sentry-element": "Link",
                        "data-sentry-source-file": "VisualizerSubtext.tsx",
                        children: "Privacy Policy"
                    }), ". 4. We recommend using Chrome (Audio quality may be degraded in iOS/Safari 17.5)."]
                })
            }
            let eS = (e, t) => {
                let {
                    pageData: a,
                    visualizerProps: s
                } = e;
                return (0, n.jsx)(l.A, {
                    research: !0,
                    "data-sentry-element": "PageWrapper",
                    "data-sentry-component": "ResearchPreview25",
                    "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                    children: (0, n.jsx)(o.A, {
                        "data-sentry-element": "ResearchPageLayout",
                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                        children: (0, n.jsxs)("div", {
                            className: "flex flex-col gap-[var(--s46)]  pb-[var(--s80)] md:pb-[var(--s120)]",
                            children: [(0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s60)]",
                                children: [(0, n.jsxs)("h1", {
                                    className: "text-h1",
                                    children: [(0, n.jsxs)("span", {
                                        className: "block md:inline md:whitespace-nowrap",
                                        children: ["Crossing the", " "]
                                    }), (0, n.jsx)("span", {
                                        className: "block md:inline md:whitespace-nowrap",
                                        children: "uncanny valley of"
                                    }), (0, n.jsx)("span", {
                                        className: "block md:whitespace-nowrap",
                                        children: "conversational voice"
                                    })]
                                }), (0, n.jsxs)("div", {
                                    children: [(0, n.jsxs)("div", {
                                        className: "flex flex-col gap-y-[var(--s6)] pb-[var(--s32)]",
                                        children: [(0, n.jsx)("div", {
                                            children: (0, n.jsx)("p", {
                                                className: "text-body text-tertiary",
                                                children: "February 27, 2025"
                                            })
                                        }), (0, n.jsx)("div", {
                                            children: (0, n.jsxs)("p", {
                                                className: "text-body text-tertiary",
                                                children: [(0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Brendan Iribe"
                                                }), ",", " ", (0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Ankit Kumar"
                                                }), ", and the Sesame team"]
                                            })
                                        })]
                                    }), (0, n.jsx)("div", {
                                        className: "line"
                                    })]
                                })]
                            }), (0, n.jsx)("div", {
                                children: (0, n.jsx)(ex.A, {
                                    href: Y.A.demo,
                                    label: "Try our demo",
                                    nopush: !0,
                                    icon: (0, n.jsx)(ej, {}),
                                    color: "grey",
                                    anchor: !0,
                                    "data-sentry-element": "LinkButton",
                                    "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                })
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s46)]",
                                children: [(0, n.jsx)("div", {
                                    children: (0, n.jsx)("p", {
                                        className: "text-body",
                                        children: (0, n.jsxs)("span", {
                                            className: "text-tertiary",
                                            children: ["How do we know when someone truly understands us? It is rarely just our words—it is in the subtleties of voice: the rising excitement, the thoughtful pause, the warm reassurance.", (0, n.jsx)("br", {}), (0, n.jsx)("br", {}), "Voice is our most intimate medium as humans, carrying layers of meaning through countless variations in tone, pitch, rhythm, and emotion.", (0, n.jsx)("br", {}), (0, n.jsx)("br", {}), "Today’s digital voice assistants lack essential qualities to make them truly useful. Without unlocking the full power of voice, they cannot hope to effectively collaborate with us. A personal assistant who speaks only in a neutral tone has difficulty finding a permanent place in our daily lives after the initial novelty wears off.", (0, n.jsx)("br", {}), (0, n.jsx)("br", {}), "Over time this emotional flatness becomes more than just disappointing—it becomes exhausting."]
                                        })
                                    })
                                }), (0, n.jsxs)("div", {
                                    children: [(0, n.jsx)("h3", {
                                        className: "text-research-h2",
                                        children: "Achieving voice presence"
                                    }), (0, n.jsx)("p", {
                                        className: "mt-[var(--s20)] text-body",
                                        children: (0, n.jsx)("span", {
                                            className: "text-tertiary",
                                            children: "At Sesame, our goal is to achieve “voice presence”—the magical quality that makes spoken interactions feel real, understood, and valued. We are creating conversational partners that do not just process requests; they engage in genuine dialogue that builds confidence and trust over time. In doing so, we hope to realize the untapped potential of voice as the ultimate interface for instruction and understanding."
                                        })
                                    })]
                                }), (0, n.jsxs)("div", {
                                    children: [(0, n.jsx)("h3", {
                                        className: "text-research-h2",
                                        children: "Key components"
                                    }), (0, n.jsx)("div", {
                                        className: "mt-[var(--s20)] text-body",
                                        children: (0, n.jsx)("div", {
                                            className: "text-tertiary",
                                            children: (0, n.jsxs)("ul", {
                                                className: "pl-[var(--s16)]",
                                                style: {
                                                    listStyleType: "disc"
                                                },
                                                children: [(0, n.jsx)("li", {
                                                    children: "Emotional intelligence: reading and responding to emotional contexts."
                                                }), (0, n.jsx)("li", {
                                                    children: "Conversational dynamics: natural timing, pauses, interruptions and emphasis."
                                                }), (0, n.jsx)("li", {
                                                    children: "Contextual awareness: adjusting tone and style to match the situation."
                                                }), (0, n.jsx)("li", {
                                                    children: "Consistent personality: maintaining a coherent, reliable and appropriate presence."
                                                })]
                                            })
                                        })
                                    })]
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-0 md:gap-[var(--s46)]",
                                children: [(0, n.jsxs)("div", {
                                    children: [(0, n.jsx)("h3", {
                                        className: "text-research-h2",
                                        children: "We’re not there yet "
                                    }), (0, n.jsx)("p", {
                                        className: "mt-[var(--s20)] text-body",
                                        children: (0, n.jsx)("span", {
                                            className: "text-tertiary",
                                            children: "Building a digital companion with voice presence is not easy, but we are making steady progress on multiple fronts, including personality, memory, expressivity and appropriateness. This demo is a showcase of some of our work in conversational speech generation. The companions shown here have been optimized for friendliness and expressivity to illustrate the potential of our approach."
                                        })
                                    }), (0, n.jsx)("div", {
                                        id: "demo"
                                    })]
                                }), (0, n.jsx)("div", {
                                    className: "pt-[var(--s60)] md:pt-0",
                                    children: (0, n.jsxs)("div", {
                                        className: "flex flex-col gap-[var(--s20)] pt-[var(--s20)]",
                                        children: [(0, n.jsx)("h3", {
                                            className: "text-research-h2",
                                            children: "Conversational voice demo"
                                        }), (0, n.jsx)(ep, {
                                            visualizerProps: s,
                                            sesameLogo: a.callButton.sesameLogo,
                                            mayaLogo: a.callButton.mayaLogo,
                                            milesLogo: a.callButton.milesLogo,
                                            textScale: a.callButton.textScale,
                                            "data-sentry-element": "Visualizer",
                                            "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                        }), (0, n.jsx)(e_, {
                                            "data-sentry-element": "VisualizerSubtext",
                                            "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                        })]
                                    })
                                })]
                            }), (0, n.jsx)("div", {
                                id: "technical"
                            }), (0, n.jsx)("div", {
                                className: "line"
                            }), (0, n.jsxs)("div", {
                                children: [(0, n.jsx)("p", {
                                    className: "text-body text-tertiary pb-[var(--s8)]",
                                    children: "Technical post"
                                }), (0, n.jsxs)("h1", {
                                    className: "text-research-h1 mb-[var(--s40)]",
                                    children: [(0, n.jsx)("span", {
                                        className: "block md:inline",
                                        children: "Conversational"
                                    }), (0, n.jsx)("span", {
                                        className: "block md:inline",
                                        children: " speech generation"
                                    })]
                                }), (0, n.jsx)("div", {
                                    children: (0, n.jsx)("div", {
                                        className: "grid grid-cols-7 gap-[var(--s24)] sm:gap-[var(--s8)] gap-y-[var(--s24)] pb-[var(--s32)]",
                                        children: (0, n.jsxs)("div", {
                                            className: (0, j.A)("col-start-1 col-end-8", "md:col-start-1 sm:col-end-5", "lg:col-start-1 lg:col-end-6"),
                                            children: [(0, n.jsx)("p", {
                                                className: "text-body",
                                                children: "Authors"
                                            }), (0, n.jsxs)("p", {
                                                className: "text-body text-tertiary",
                                                children: [(0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Johan Schalkwyk"
                                                }), ",", " ", (0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Ankit Kumar"
                                                }), ",", " ", (0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Dan Lyth"
                                                }), ",", " ", (0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Sefik Emre Eskimez"
                                                }), ", ", (0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Zack Hodari"
                                                }), ",", " ", (0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Cinjon Resnick"
                                                }), ",", " ", (0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Ramon Sanabria"
                                                }), ",", " ", (0, n.jsx)("span", {
                                                    className: "whitespace-nowrap",
                                                    children: "Raven Jiang"
                                                })]
                                            })]
                                        })
                                    })
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary mt-[var(--s20)]",
                                    children: ["To create AI companions that feel genuinely interactive, speech generation must go beyond producing high-quality audio—it must understand and adapt to context in real time. Traditional text-to-speech (TTS) models generate spoken output directly from text but lack the contextual awareness needed for natural conversations. Even though recent models produce highly human-like speech, they struggle with the one-to-many problem: there are countless valid ways to speak a sentence, but only some fit a given setting. Without additional context—including tone, rhythm, and history of the conversation—models lack the information to choose the best option. Capturing these nuances requires reasoning across multiple aspects of language and prosody.", (0, n.jsx)("br", {}), (0, n.jsx)("br", {}), "To address this, we introduce the Conversational Speech Model (CSM), which frames the problem as an end-to-end multimodal learning task using transformers. It leverages the history of the conversation to produce more natural and coherent speech. There are two key takeaways from our work. The first is that CSM operates as a", " ", (0, n.jsx)("span", {
                                        className: "text-main",
                                        children: "single-stage model"
                                    }), ", thereby improving efficiency and expressivity. The second is our", " ", (0, n.jsx)("span", {
                                        className: "text-main",
                                        children: "evaluation suite"
                                    }), ", which is necessary for evaluating progress on contextual capabilities and addresses the fact that common public evaluations are saturated."]
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Background"
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["One approach to modeling audio with transformers is to convert continuous waveforms into discrete audio token sequences using tokenizers. Most contemporary approaches (", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.ref1,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "[1]"
                                    }), ",", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.ref2,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "[2]"
                                    }), ") rely on two types of audio tokens:"]
                                }), (0, n.jsxs)("ol", {
                                    className: "text-body text-tertiary list-decimal pl-[var(--s24)]",
                                    children: [(0, n.jsxs)("li", {
                                        children: [(0, n.jsx)("span", {
                                            className: "text-main",
                                            children: "Semantic tokens"
                                        }), ": Compact speaker-invariant representations of semantic and phonetic features. Their compressed nature enables them to capture key speech characteristics at the cost of high-fidelity representation."]
                                    }), (0, n.jsxs)("li", {
                                        children: [(0, n.jsx)("span", {
                                            className: "text-main",
                                            children: "Acoustic tokens"
                                        }), ": Encodings of fine-grained acoustic details that enable high-fidelity audio reconstruction. These tokens are often generated using Residual Vector Quantization (RVQ)", " ", (0, n.jsx)(eg(), {
                                            href: Y.A.researchRefs.ref2,
                                            className: "underline",
                                            target: "_blank",
                                            rel: "noopener noreferrer",
                                            "data-sentry-element": "NextLink",
                                            "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                            children: "[2]"
                                        }), ". In contrast to semantic tokens, acoustic tokens retain natural speech characteristics like speaker-specific identity and timbre."]
                                    })]
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "A common strategy first models semantic tokens and then generates audio using RVQ or diffusion-based methods. Decoupling these steps allows for a more structured approach to speech synthesis—the semantic tokens provide a compact, speaker-invariant representation that captures high-level linguistic and prosodic information, while the second-stage reconstructs the fine-grained acoustic details needed for high-fidelity speech. However, this approach has a critical limitation; semantic tokens are a bottleneck that must fully capture prosody, but ensuring this during training is challenging."
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["RVQ-based methods introduce their own set of challenges. Models must account for the sequential dependency between codebooks in a frame. One method, the delay pattern (figure below)", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.ref3,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "[3]"
                                    }), ", shifts higher codebooks progressively to condition predictions on lower codebooks within the same frame. A key limitation of this approach is that the time-to-first-audio scales poorly because an RVQ tokenizer with N codebooks requires N backbone steps before decoding the first audio chunk. While suitable for offline applications like audiobooks, this delay is problematic in a real-time scenario."]
                                }), (0, n.jsx)("div", {
                                    className: "w-full overflow-hidden rounded-radius2 relative",
                                    children: (0, n.jsx)(i.A, {
                                        src: "/assets/images/researchgraph/sequence.jpg",
                                        width: 624,
                                        height: 448,
                                        color: "white",
                                        alt: "Example of delayed pattern generation in an RVQ tokenizer with 4 codebooks",
                                        "data-sentry-element": "Image",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })
                                }), (0, n.jsx)("p", {
                                    className: "text-caption-sm text-tertiary px-[var(--s24)]",
                                    children: "Example of delayed pattern generation in an RVQ tokenizer with 4 codebooks"
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Conversational Speech Model"
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["CSM is a multimodal, text and speech model that operates directly on RVQ tokens. Inspired by the RQ-Transformer", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.ref4,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "[4]"
                                    }), ", we use two autoregressive transformers. Different from the approach in", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.ref5,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "[5]"
                                    }), ", we split the transformers at the zeroth codebook. The first", (0, n.jsx)("span", {
                                        className: "text-main",
                                        children: " multimodal backbone"
                                    }), " processes interleaved text and audio to model the zeroth codebook. The second ", (0, n.jsx)("span", {
                                        className: "text-main",
                                        children: "audio decoder"
                                    }), " uses a distinct linear head for each codebook and models the remaining N\xa0–\xa01 codebooks to reconstruct speech from the backbone’s representations. The decoder is significantly smaller than the backbone, enabling low-latency generation while keeping the model end-to-end."]
                                }), (0, n.jsx)("div", {
                                    className: "w-full overflow-hidden rounded-radius2 relative",
                                    children: (0, n.jsx)(i.A, {
                                        src: "/assets/images/researchgraph/architecture.jpg",
                                        width: 624,
                                        height: 487,
                                        color: "white",
                                        alt: "CSM model inference process",
                                        "data-sentry-element": "Image",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })
                                }), (0, n.jsx)("p", {
                                    className: "text-caption-sm text-tertiary px-[var(--s24)]",
                                    children: "CSM model inference process. Text (T) and audio (A) tokens are interleaved and fed sequentially into the Backbone, which predicts the zeroth level of the codebook. The Decoder then samples levels 1 through N\xa0–\xa01 conditioned on the predicted zeroth level. The reconstructed audio token (A) is then autoregressively fed back into the Backbone for the next step, continuing until the audio EOT symbol is emitted. This process begins again on the next inference request, with the interim audio (such as a user utterance) being represented by interleaved audio and text transcription tokens."
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["Both transformers are variants of the Llama architecture. Text tokens are generated via a Llama tokenizer", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.ref6,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "[6]"
                                    }), ", while audio is processed using Mimi, a split-RVQ tokenizer, producing one semantic codebook and N\xa0–\xa01 acoustic codebooks per frame at 12.5\xa0Hz.", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.ref5,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "[5]"
                                    }), " ", "Training samples are structured as alternating interleaved patterns of text and audio, with speaker identity encoded directly in the text representation."]
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Compute amortization"
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "This design introduces significant infrastructure challenges during training. The audio decoder processes an effective batch size of B\xa0\xd7\xa0S and N codebooks autoregressively, where B is the original batch size, S is the sequence length, and N is the number of RVQ codebook levels. This high memory burden even with a small model slows down training, limits model scaling, and hinders rapid experimentation, all of which are crucial for performance."
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "To address these challenges, we use a compute amortization scheme that alleviates the memory bottleneck while preserving the fidelity of the full RVQ codebooks. The audio decoder is trained on only a random 1/16 subset of the audio frames, while the zeroth codebook is trained on every frame. We observe no perceivable difference in audio decoder losses during training when using this approach."
                                }), (0, n.jsx)("div", {
                                    className: "w-full overflow-hidden rounded-radius2 relative",
                                    children: (0, n.jsx)(i.A, {
                                        src: "/assets/images/researchgraph/amortization.jpg",
                                        width: 624,
                                        height: 384,
                                        color: "white",
                                        alt: "Amortized training process",
                                        "data-sentry-element": "Image",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })
                                }), (0, n.jsx)("p", {
                                    className: "text-caption-sm text-tertiary px-[var(--s24)]",
                                    children: "Amortized training process. The backbone transformer models the zeroth level across all frames (highlighted in blue), while the decoder predicts the remaining N\xa0–\xa031 levels, but only for a random 1/16th of the frames (highlighted in green). The top section highlights the specific frames modeled by the decoder for which it receives loss."
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Experiments"
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: [(0, n.jsx)("span", {
                                        className: "text-main",
                                        children: "Dataset"
                                    }), ": We use a large dataset of publicly available audio, which we transcribe, diarize, and segment. After filtering, the dataset consists of approximately one million hours of predominantly English audio."]
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: [(0, n.jsx)("span", {
                                        className: "text-main",
                                        children: "Model Sizes"
                                    }), ": We trained three model sizes, delineated by the backbone and decoder sizes:"]
                                }), (0, n.jsxs)("ul", {
                                    className: "text-body text-tertiary list-disc pl-[var(--s24)]",
                                    children: [(0, n.jsxs)("li", {
                                        children: [(0, n.jsx)("span", {
                                            className: "text-main",
                                            children: "Tiny"
                                        }), ": 1B backbone, 100M decoder"]
                                    }), (0, n.jsxs)("li", {
                                        children: [(0, n.jsx)("span", {
                                            className: "text-main",
                                            children: "Small"
                                        }), ": 3B backbone, 250M decoder"]
                                    }), (0, n.jsxs)("li", {
                                        children: [(0, n.jsx)("span", {
                                            className: "text-main",
                                            children: "Medium"
                                        }), ": 8B backbone, 300M decoder"]
                                    })]
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "Each model was trained with a 2048 sequence length (~2 minutes of audio) over five epochs."
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Samples"
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "Paralinguistics"
                                }), (0, n.jsxs)("div", {
                                    className: "flex md:flex-row flex-col gap-[var(--s12)]",
                                    children: [(0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_paralinguistics_01.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    }), (0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_paralinguistics_02.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })]
                                }), (0, n.jsxs)("p", {
                                    className: "text-caption-sm text-tertiary",
                                    children: ["Sentences from", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.baseTTS,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "Base TTS"
                                    })]
                                }), (0, n.jsx)("p", {}), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "Foreign words"
                                }), (0, n.jsxs)("div", {
                                    className: "flex md:flex-row flex-col gap-[var(--s12)]",
                                    children: [(0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_foreign_words_01.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    }), (0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_foreign_words_02.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })]
                                }), (0, n.jsxs)("p", {
                                    className: "text-caption-sm text-tertiary",
                                    children: ["Sentences from", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.baseTTS,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "Base TTS"
                                    })]
                                }), (0, n.jsx)("p", {}), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "Contextual expressivity"
                                }), (0, n.jsxs)("div", {
                                    className: "flex md:flex-row flex-col gap-[var(--s12)]",
                                    children: [(0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_contextual_expressive_01.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    }), (0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_contextual_expressive_02.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })]
                                }), (0, n.jsx)("p", {
                                    className: "text-caption-sm text-tertiary",
                                    children: "Samples from Expresso, continuation after chime"
                                }), (0, n.jsx)("p", {}), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "Pronunciation correction"
                                }), (0, n.jsxs)("div", {
                                    className: "flex md:flex-row flex-col gap-[var(--s12)]",
                                    children: [(0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_pronunciation_correction_01.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    }), (0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_pronunciation_correction_02.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })]
                                }), (0, n.jsx)("p", {
                                    className: "text-caption-sm text-tertiary",
                                    children: "Pronunciation correction sentence is a recording, all other audio is generated."
                                }), (0, n.jsx)("p", {}), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "Conversations with multiple speakers"
                                }), (0, n.jsx)("div", {
                                    className: "flex md:flex-row flex-col gap-[var(--s12)]",
                                    children: (0, n.jsx)(c, {
                                        src: "https://storage.googleapis.com/sesame-dev-public/audio/blog/sesame_conversation_01.wav",
                                        "data-sentry-element": "AudioPlayer",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })
                                }), (0, n.jsx)("p", {
                                    className: "text-caption-sm text-tertiary",
                                    children: "Single generation using audio prompts from two speakers"
                                }), (0, n.jsx)("p", {})]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Evaluation"
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["Our evaluation suite measures model performance across four key aspects: faithfulness to text, context utilization, prosody, and latency. We report both objective and subjective metrics—objective benchmarks include word error rate and novel tests like homograph disambiguation, while subjective evaluation relies on a Comparative Mean Opinion Score (CMOS) human study using the ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.expresso,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "Expresso"
                                    }), " ", "dataset."]
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Objective metrics"
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "Traditional benchmarks, such as word error rate (WER) and speaker similarity (SIM), have become saturated—modern models, including CSM, now achieve near-human performance on these metrics."
                                }), (0, n.jsx)("div", {
                                    className: "w-full overflow-hidden rounded-radius2 relative",
                                    children: (0, n.jsx)(i.A, {
                                        src: "/assets/images/researchgraph/WER+SS.jpg",
                                        width: 624,
                                        height: 387,
                                        color: "white",
                                        alt: "Objective metric results for Word Error Rate and Speaker Similarity tests",
                                        "data-sentry-element": "Image",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })
                                }), (0, n.jsx)("p", {
                                    className: "text-caption-sm text-tertiary px-[var(--s24)]",
                                    children: "Objective metric results for Word Error Rate (top) and Speaker Similarity (bottom) tests, showing the metrics are saturated (matching human performance)."
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "To better assess pronunciation and contextual understanding, we introduce a new set of phonetic transcription-based benchmarks."
                                }), (0, n.jsxs)("ul", {
                                    className: "text-body text-tertiary list-disc pl-[var(--s24)] flex flex-col gap-[var(--s16)]",
                                    children: [(0, n.jsxs)("li", {
                                        children: [(0, n.jsx)("span", {
                                            className: "font-semibold text-main",
                                            children: "Text understanding through Homograph Disambiguation:"
                                        }), " ", "Evaluates whether the model correctly pronounced different words with the same orthography (e.g., “lead” /lɛd/ as in “metal” vs. “lead” /liːd/ as in “to guide”)."]
                                    }), (0, n.jsxs)("li", {
                                        children: [(0, n.jsx)("span", {
                                            className: "font-semibold text-main",
                                            children: "Audio understanding through Pronunciation Continuation Consistency:"
                                        }), " ", "Evaluates whether the model maintains pronunciation consistency of a specific word with multiple pronunciation variants in multi-turn speech. One example is “route” (/raʊt/ or /ruːt/), which can vary based on region of the speaker and context."]
                                    })]
                                }), (0, n.jsx)("div", {
                                    className: "w-full overflow-hidden rounded-radius2 relative",
                                    children: (0, n.jsx)(i.A, {
                                        src: "/assets/images/researchgraph/Eval.jpg",
                                        width: 624,
                                        height: 303,
                                        color: "white",
                                        alt: "Objective metric results for Homograph Disambiguation and Pronunciation Consistency tests",
                                        "data-sentry-element": "Image",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })
                                }), (0, n.jsx)("p", {
                                    className: "text-caption-sm text-tertiary px-[var(--s24)]",
                                    children: "Objective metric results for Homograph Disambiguation (left) and Pronunciation Consistency (right) tests, showing the accuracy percentage for each model’s correct pronunciation. Play.ht, Elevenlabs, and OpenAI generations were made with default settings and voices from their respective API documentation."
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["The graph above compares objective metric results across three model sizes. For Homograph accuracy we generated 200 speech samples covering 5 distinct homographs—lead, bass, tear, wound, row—with 2 variants for each and evaluated pronunciation consistency using", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.wav2vec2,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "wav2vec2-lv-60-espeak-cv-ft"
                                    }), ". For Pronunciation Consistency we generated 200 speech samples covering 10 distinct words that have common pronunciation variants—aunt, data, envelope, mobile, route, vase, either, adult, often, caramel."]
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "In general, we observe that performance improves with larger models, supporting our hypothesis that scaling enhances the synthesis of more realistic speech."
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Subjective metrics"
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["We conducted two Comparative Mean Opinion Score (CMOS) studies using the", " ", (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.expresso,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "Expresso"
                                    }), " ", "dataset to assess the naturalness and prosodic appropriateness of generated speech for CSM-Medium. Human evaluators were presented with pairs of audio samples—one generated by the model and the other a ground-truth human recording. Listeners rated the generated sample on a 7-point preference scale relative to the reference. Expresso’s diverse expressive TTS samples, including emotional and prosodic variations, make it a strong benchmark for evaluating appropriateness to context."]
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["In the first CMOS study we presented the generated and human audio samples with no context and asked listeners to", " ", (0, n.jsx)("span", {
                                        className: "italic",
                                        children: "“choose which rendition feels more like human speech.”"
                                    }), " ", "In the second CMOS study we also provide the previous 90 seconds of audio and text context, and ask the listeners to", " ", (0, n.jsx)("span", {
                                        className: "italic",
                                        children: "“choose which rendition feels like a more appropriate continuation of the conversation.”"
                                    }), " ", "Eighty people were paid to participate in the evaluation and rated on average 15 examples each."]
                                }), (0, n.jsx)("div", {
                                    className: "w-full overflow-hidden rounded-radius2 relative",
                                    children: (0, n.jsx)(i.A, {
                                        src: "/assets/images/researchgraph/subjective.jpg",
                                        width: 624,
                                        height: 343,
                                        color: "white",
                                        alt: "Subjective evaluation results on the Expresso dataset",
                                        "data-sentry-element": "Image",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    })
                                }), (0, n.jsxs)("p", {
                                    className: "text-caption-sm text-tertiary px-[var(--s24)]",
                                    children: ["Subjective evaluation results on the Expresso dataset. No context: listeners chose", " ", (0, n.jsx)("span", {
                                        className: "italic",
                                        children: "“which rendition feels more like human speech”"
                                    }), " ", "without knowledge of the context. Context: listeners chose", " ", (0, n.jsx)("span", {
                                        className: "italic",
                                        children: "“which rendition feels like a more appropriate continuation of the conversation”"
                                    }), " ", "with audio and text context. 50:50 win–loss ratio suggests that listeners have no clear preference."]
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "The graph above shows the win-rate of ground-truth human recordings vs CSM-generated speech samples for both studies. Without conversational context (top), human evaluators show no clear preference between generated and real speech, suggesting that naturalness is saturated. However, when context is included (bottom), evaluators consistently favor the original recordings. These findings suggest a noticeable gap remains between generated and human prosody in conversational speech generation."
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Open-sourcing our work"
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "We believe that advancing conversational AI should be a collaborative effort. To that end, we’re committed to open-sourcing key components of our research, enabling the community to experiment, build upon, and improve our approach. Our models will be available under an Apache 2.0 license."
                                }), (0, n.jsxs)("div", {
                                    className: "text-body text-tertiary underline flex items-center gap-[var(--s10)]",
                                    children: [(0, n.jsx)(eN.A, {
                                        className: "w-[var(--s20)] h-[var(--s20)]",
                                        "data-sentry-element": "LinkIcon",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx"
                                    }), (0, n.jsx)(eg(), {
                                        href: Y.A.researchRefs.github,
                                        className: "underline",
                                        target: "_blank",
                                        rel: "noopener noreferrer",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "Check out our GitHub for updates and contributions"
                                    })]
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Limitations and future work"
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "CSM is currently trained on primarily English data; some multilingual ability emerges due to dataset contamination, but it does not perform well yet. It also does not take advantage of the information present in the weights of pre-trained language models."
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "In the coming months, we intend to scale up model size, increase dataset volume, and expand language support to over 20 languages. We also plan to explore ways to utilize pre-trained language models, working towards large multimodal models that have deep knowledge of both speech and text."
                                }), (0, n.jsx)("p", {
                                    className: "text-body text-tertiary",
                                    children: "Ultimately, while CSM generates high quality conversational prosody, it can only model the text and speech content in a conversation—not the structure of the conversation itself. Human conversations are a complex process involving turn taking, pauses, pacing, and more. We believe the future of AI conversations lies in fully duplex models that can implicitly learn these dynamics from data. These models will require fundamental changes across the stack, from data curation to post-training methodologies, and we’re excited to push in these directions."
                                })]
                            }), (0, n.jsxs)("div", {
                                className: "flex flex-col gap-[var(--s20)]",
                                children: [(0, n.jsx)("h3", {
                                    className: "text-research-h2",
                                    children: "Join us"
                                }), (0, n.jsxs)("p", {
                                    className: "text-body text-tertiary",
                                    children: ["If you’re excited about building the most natural, delightful, and inspirational voice interfaces out there, reach out—we’re hiring. Check our", " ", (0, n.jsx)(eg(), {
                                        target: "_blank",
                                        href: Y.A.openRoles,
                                        rel: "noopener noreferrer",
                                        className: "underline",
                                        "data-sentry-element": "NextLink",
                                        "data-sentry-source-file": "crossing_the_uncanny_valley_of_voice.tsx",
                                        children: "open roles"
                                    }), "."]
                                })]
                            })]
                        })
                    })
                })
            };
            eS.displayName = "ResearchPreview25";
            var eA = !0;
            let eM = (0, r.forwardRef)(eS)
        },
        7882: (e, t, a) => {
            "use strict";
            let s;
            a.d(t, {
                Q: () => f
            });
            var n = a(6540);
            let r = e => {
                let t = (0, n.useRef)(e);
                return (0, n.useEffect)(() => {
                    t.current = e
                }, [e]), t
            };
            var i = a(3949);
            let l = new Set,
                o = e => {
                    l.forEach(t => {
                        var a;
                        null === (a = t.current) || void 0 === a || a.call(t, e)
                    })
                },
                c = () => {
                    let e = !1;
                    if ("maxTouchPoints" in navigator) e = navigator.maxTouchPoints > 0;
                    else if ("msMaxTouchPoints" in navigator) e = navigator.msMaxTouchPoints > 0;
                    else {
                        let t = window.matchMedia && matchMedia("(pointer:coarse)");
                        if (t && "(pointer:coarse)" === t.media) e = !!t.matches;
                        else if ("orientation" in window) e = !0;
                        else {
                            let t = navigator.userAgent;
                            e = /\b(BlackBerry|webOS|iPhone|IEMobile)\b/i.test(t) || /\b(Android|Windows Phone|iPad|iPod)\b/i.test(t)
                        }
                    }
                    return e && window.innerWidth < i.f.MS
                },
                d = {
                    width: 0,
                    height: 0
                },
                u = null,
                h = () => {
                    clearTimeout(u), u = setTimeout(() => {
                        void 0 === s && (s = c());
                        let e = {
                                width: window.innerWidth,
                                height: window.innerHeight
                            },
                            t = s && d.width === e.width;
                        d.width = e.width, d.height = e.height, t || o(e)
                    }, 1)
                },
                m = !1,
                p = "resize",
                f = function(e) {
                    let {
                        fireOnInitialRender: t = !1
                    } = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {}, a = r(e);
                    (0, n.useEffect)(() => (l.add(a), m || (d.width = window.innerWidth, d.height = window.innerHeight, window.addEventListener(p, h), m = !0), t && a.current(d), () => {
                        l.delete(a), 0 === l.size && (window.removeEventListener(p, h), m = !1)
                    }), [a, t])
                }
        }
    },
    e => {
        var t = t => e(e.s = t);
        e.O(0, [965, 764, 407, 340, 636, 593, 792], () => t(5072)), _N_E = e.O()
    }
]);